[{"title":"Yanray训练手札","url":"/p/27917125.html","content":"\n记录训练Yanray的一部分想法。\n\n> 该文章会长期更新。\n\n<!-- more -->\n\n## 2024-05-02 记1\n其实很早就有自己定制一个AI Assitant的想法了，大约22年3.5刚出的时候就幻想自己做一个Virtual GirlFriend。可惜当时忙着应付考试，也就止步于幻想。\n\n所有的LLM（Large Language Model）本质上都是文本预测器，是在预测一段文本接下来会输出什么。而不论ChatGPT、Claude还是ChatGLM、Qwen，追根到底都是让模型预测一段文本中“Assistant”会说什么。本质上输入模型的格式都是如下所示：\n\n```\nSystem: You are an assitant.Your name is Yanray. \nUser: <|input|>\nAssitant: <|output|>\n```\n\ninput为用户输入的问题，模型只要补齐在这段对话里面Assitant会输出什么就行了，然后Filter单独把模型的输出作为output截出来，包装好丢给api出口，在用户看起来，就是一个聊天机器人。\n\n事实上做一个属于自己的AI Assitant很简单，也不需要太大的资源。我的最初的设想是一个比较小巧（6B-13B）的LLM作为一个主模型，合理使用各类工具API加持（比如浏览器、计算器之类）。只要给LLM一些最基本的语言逻辑，还要“教”会LLM输出指定的格式能够被Filter检测并调用，并且LLM要会正确读取Filter返回的数据即可。例如：\n\n```\nSystem: `/calculate` can use calculate tools\nUser: pls calculate 6.5*7.5\n```\n\n模型只要能正确输出`/calculate 6.5*7.5`，Filter就能拦截命令，直接计算数据，然后补齐在对话内：\n\n```\n<<...\nAssitant: /calculate 6.5*7.5\nTools: 48.75\nAssitant: Result is 48.75\n```\n\n包括让模型上网都可以用这种简单的方式实现。不过据我之前随手查询的资料，langchain貌似已经很好的做到了这一点。今天把手头的B事处理完之后去看一下langchain部署的难易度，如果实在麻烦不如直接将使用方式作为prompt丢给模型，“教”它简单使用就行，反正做Yanray就是给自己爽的，没必要用什么很高大上的东西。\n\n目前计划采用的主模型是ChatGLM3-6B-32K，主要是够小，压着精度能够跑在我P102上，而且如果可以的话用LLaMA Factory在本机上跑微调或者Lora，10G虽然够呛，P102算力也难绷，但是能跑就行。\n","tags":["LLM","微调模型"],"categories":["随心扯"]},{"title":"为什么我更想要FullCone网络","url":"/p/daa17206.html","content":"\nFullCone是什么？我是如何利用FullCone网络实现内网穿透的？为什么我会这么希望得到全锥网络？\n\n<!--more-->\n\n---\n\n寒假的时候几个高中同学凑一块，想联机玩Minecraft。然而我们几个同学都没有公网ip，想要联机必须要内网穿透。\n\n> 为什么不用IPV6？因为除了我之外其他人的路由器都是NAT在运营商给的智慧网关下，而智慧网关并不支持在NAT中分配IPV6。\n\n传统内网穿透，本质上是用户之间无法直接连接，只能通过一台大家都能连上的服务器互相转发流量，达到穿透的目的。\n\n显而易见，这种方式的互联受限于服务器的带宽和延迟，而且为了转发流量而单独购买一台服务器并不值得。\n\n有没有一种方式，能让两个相互处于NAT网络的用户直接连接，而不需要服务器转发流量呢？\n\n在这之前，我们不妨回过头来，聊聊生活中司空见惯的NAT技术。\n\n## What is NAT\n\nNAT(Network Address Translation)是网络地址转换的缩写，是一种将私有网络地址转换为公有网络地址的技术，诞生的目的是为了解决IPv4地址不足的问题。其解决方案是将多个设备处于一个局域网内，通过共享一个公网ip地址来访问外部网络。\n\n一个传统的网络链接，本质上是两个（ip地址:端口）之间的通讯。NAT通过类似中间人的方式，转发了（公网ip:端口）和（内网ip:端口）之间的通讯。\n\n![图源来自维基百科](https://registry.npmmirror.com/chenyfan-os/0.0.0-r25/files/article/1.png)\n\n不妨用我访问`https://baidu.com`的过程来举例：\n\n0. 路由器通过拨号上网，获取到了一个公网ip地址`39.0.0.1`。路由器网关为`192.168.1.0`，我的电脑ip为`192.168.1.1`。\n1. 浏览器通过DNS解析获取到百度的ip为`110.242.68.66`，由于我采用`https`，故默认访问端口为`443`，则目标pair为`110.242.68.66:443`\n2. 浏览器通过网卡，查询到本机ip为`192.168.1.1`，并在本地打开了一个临时端口`12345`，将数据包发送给网关`192.168.1.0`\n3. 路由器接收到来自`192.168.1.1:12345 -> 110.242.68.66:443`的请求。\n4. 路由器在本地打开了一个临时端口`54321`，将请求改写为`39.0.0.1:54321 -> 110.242.68.66:443`，并将请求数据包发送给百度服务器。同时，路由器在本地记录了这个pair的映射关系`39.0.0.1:54321 -> 192.168.1.1:12345`。\n5. 路由器接收到来自百度的返回消息`110.242.68.66:443 -> 39.0.0.1:54321`，通过查询映射关系，将返回消息改写为`110.242.68.66:443 -> 192.168.1.1:12345`，并发送给`192.168.1.1`。\n\n通过NAT技术，处在内网的用户能够主动向外部网络发起请求，并且由于路由器保持了映射关系，外部网络也能够向内网发送数据。\n\n但是，在这一情况下外部网络并不能主动向内网发起请求。由于外部网络发出请求数据后，路由表内并没有对应的pair映射关系，路由器并不知晓将外部请求转发给哪个内网用户，会直接丢弃。这就造成了内网用户可以主动链接外部网络，而外部网络却不能主动链接内网用户的局面。\n\n别急，让我们重新审视一下这个过程中最关键的部分：**路由器在本地记录了映射关系**，这才能允许外网向内网发送数据。\n\n如果想要达到外网主动链接内网的目的，由于映射关系只能通过内网用户发起请求或者路由器主动打开，我们的思路应该着重于如何主动获取并保持这个映射关系。\n\n映射关系在内网用户主动发起请求的时候建立，而销毁映射关系的策略则略有不同。由于TCP链接为有状态的链接，路由器会在链接主动关闭时自动销毁映射关系。而UDP链接则不同，由于UDP链接是无状态的，路由器并不知晓何时销毁映射关系，只能通过一定的策略来销毁。这一策略通常是在一段时间内没有数据包通过时销毁映射关系。换句话说，在建立映射关系后，只要不断地发送心跳包，这一映射关系就能够一直保持。\n\n回头来看，这一问题的解决方案就显而易见了，在建立一个请求后通过不断发送心跳包，欺骗路由器，使其保持映射关系，就能够实现外网主动链接内网的目的。\n\n...吗？\n\n## NAT has 4 main types\n\n回头来看，事情的解决好像变得太过于简单了。固然，映射关系能够使发送至`39.0.0.1:54321`的数据包转发到`192.168.1.1:12345`，在百度的视角来看，我就像是拥有了公网ip，能够主动向`39.0.0.1:54321`发送信息。\n\n然而，NAT技术很早就考虑到了这一点。映射关系的存在固然能够使外网主动链接内网，但这使得内网用户的（ip地址:端口）彻底暴露在了外网之中。而NAT的本身是局域网，起到了与外部网络隔离的作用，这种暴露方式即不优雅，也不安全。\n\n至此，NAT根据转发策略和限制映射关系访问的方式，分为了4种类型（RFC3489）：\n\n- FullCone 全锥，映射对能够被任意外部网络访问（也被称为NAT A）\n- RestrictedCone 限制锥，映射对仅能被映射目标ip访问（丢弃除了来自`110.242.68.66`的所有数据包）\n- PortRestrictedCone 端口限制锥，映射对仅能被映射目标ip和端口访问（丢弃除了来自`110.242.68.66:443`的所有数据包）\n- Symmetric 对称，映射对仅能被映射目标ip和端口访问，并且当目的地ip和端口不同时，映射对也会不同（即使内网ip:端口是相同的）\n\n其中 全锥、限制锥、端口限制锥 最大的特征是同一个（内网ip:端口）的映射请求会被映射为相同的（公网ip:端口），无论目的地ip和端口是什么。而 对称 则会在目的地ip和端口不同时映射为不同的（公网ip:端口）。\n\n你可以用Python的pystun3来测试你的NAT类型：\n\n```shell\npip install pystun3\npystun3\npystun3 -H stun.qq.com #国内用户可以指定qq的stun服务器以加快测试速度\n```\n\n返回数据应该如下：\n\n```\nNAT Type: Full Cone\nExternal IP: 39.0.0.1\nExternal Port: 12463\n```\n\n## Let us have a try - to build up a server with FullCone NAT\n\n知道了原理，不来试试怎么加深理解呢？\n\n首先，以下操作需要一个拥有全锥NAT的网络环境。如果没有你可以看下一节内容尝试将自己的家庭网络改造为全锥NAT。\n\n此外，需要一台拥有公网ip的服务器，以便于本地计算机能够探测出映射关系。\n\n接下来，我将展示两个脚本，通过运行脚本，本地计算机能够探测出映射关系并在映射对上建立一个临时服务器，如果外部网络能够通过探测出来的映射对访问到这个临时服务器，那么就能证明FullCone内网穿透理论可行。\n\n```javascript\n//server.js\nconst http = require('http');\nconst server = http.createServer((req, res) => {\n  res.writeHead(200, { 'Content-Type': 'application/json' });\n  const ip = req.connection.remoteAddress.match(/\\d+\\.\\d+\\.\\d+\\.\\d+/)[0];\n  const port = req.connection.remotePort;\n  console.log(`Request from ${ip}:${port}`);\n  setInterval(() => {\n    try {\n      const req = http.request({\n        host: ip,\n        port: port,\n        method: 'GET'\n      })\n      req.end();\n    } catch (e) { }\n  }, 1000); //该定时器会每秒向客户端发送一个请求，使得映射关系不会因为长时间没有通信而被销毁，从而实现锁定映射关系\n  res.end(JSON.stringify({ ip, port }));\n}).listen(13000);\n```\n\n```javascript\n//client.js\nconst http = require('http');\nconst localPort = 18000; //这是本地即将暴露的端口\nconst endpoint_url = '' //这是部署了server.js的服务器的ip地址\nconst endpoint_port = 13000 //这是部署了server.js的服务器的端口\nconst req = http.request({\n    host: endpoint_url,\n    port: endpoint_port,\n    method: 'GET',\n    localPort: localPort //http.request可以通过localPort参数强制指定本地端口\n}, (res) => {\n    res.on('data', (data) => {\n        const { ip, port } = JSON.parse(data.toString());\n        console.log(`127.0.0.1:${localPort} -> ${ip}:${port}`);\n        console.log(`http://${ip}:${port}`);\n        http.createServer((req, res) => {\n            res.writeHead(200, { 'Content-Type': 'text/plain' });\n            res.end(`Working at ${new Date()}`);\n        }).listen(localPort); //通过server.js探测到映射对，然后在本地启动一个服务器，外网访问ip:port会被映射到本地的localPort，从而实现了内网穿透\n    })\n});\nreq.end();\n```\n\n先运行server.js，然后填入服务器的ip，再运行client.js，控制台内有如下输出\n\n```\n127.0.0.1:18000 -> 39.1.1.1:12319\nhttp://39.1.1.1:12319\n```\n\n脚本将会自动在`0.0.0.0:18000`启动一个测试服务器，我们直接点击链接访问`http://39.1.1.1:12319`\n\n![](https://registry.npmmirror.com/chenyfan-os/0.0.0-r25/files/article/1.jpg)\n\n如果显示了信息，说明我们的`127.0.0.1:18000`已经成功地被穿透到了`39.1.1.1:12319`。\n\n并且，将`http://39.1.1.1:12319`分享给其他人，他们也能够访问到你的本地服务器。\n\n请注意，从头到尾我并没有声明我拥有公网ip，事实上，无论是否为公网ip，只要nat类型为FullCone，都可以利用这种方式穿透。\n\n使用FullCone穿透的地址可以直接被外网访问，其优点在于流量无需服务器中转，最终的访问是点对点的，目标用户是直接访问到内网的服务器，延迟和速率不受限制。探测服务器仅用于辅助内网用户获取到自己链路上的映射对，本身不参与网络连接。并且网络上存在大量的免费探测服务器，不一定需要自己搭建的服务器。\n\n缺点也十分明显，映射对本身需要长时间的心跳包才能维持，一旦映射长时间无数据包通过，映射就会被断掉，并且重新映射的端口不固定。此外，如果作为长期暴露在公网上供他人访问，还是需要有其他方法将探测到的映射对共享出去（类似DDNS）。\n\n## STUN - A formal protocol to detect NAT pair\n\n事实上，上面的脚本只是一个简单的例子。然而，RFC5389定义了一种更加正式的协议，[STUN(Session Traversal Utilities for NAT)](https://zh.wikipedia.org/wiki/STUN)。STUN协议定义了一种用于检测NAT类型和获取映射对的协议，其探测协议为UDP。由于基于UDP的探测对不会在断开连接后立刻销毁，STUN协议能够有更大的成功率实现NAT互联。\n\n> 需要注意的是，部分路由器在建立映射对的时候也会限制协议。如果内网内用户用UDP探测，则部分路由器只会允许UDP协议的映射对，而不会允许TCP数据包通过映射对。反之亦然。\n>\n> 如同上面的Demo中，我利用TCP协议来探测映射对，因此外网只能用TCP协议（HTTP协议基于TCP）访问到我的内网服务器，而外网服务器尝试向映射对发送UDP数据包，路由器则会直接丢弃。\n> \n> 然而，我们可以将TCP包装在UDP之中，从而绕过这一限制。这一技术被称为TCP over UDP。\n>\n> 从另一方面讲，基于UDP的VPN协议并不罕见，通过STUN打洞后完全可以建立一个基于UDP的虚拟局域网用于传递TCP数据包，例如传统的Wireguard协议。\n> \n> 此外，STUN可以利用TCP作为探测协议，但是在实际网络环境中并非所有NAT均为全锥NAT，因此TCP探测的成功率并不高。\n\n这是标准（RFC 3489）中的利用STUN来探测映射对和NAT类型的过程：\n\n![图源来自维基百科](https://registry.npmmirror.com/chenyfan-os/0.0.0-r25/files/article/2.png)\n\n---\n\n## NAT2NAT - If we all can not get a Public IP\n\n上面所讲述的内容，都是在拥有FullCone的前提下，内网穿透了自己的ip到公网上。然而在大多数使用场景内，我们并不需要把自己的ip暴露在公网上，而是需要两个内网用户之间能够直接链接。\n\n而NAT2NAT技术可以很好的解决这一问题，N2N并不依赖于FullCone就可以尝试在两个NAT用户间“打洞”，使得两个内网用户“直接”互相链接，无需经过服务器转发。\n\n> 然而，拥有FullCone的打洞成功率接近100%，而其他类型的NAT打洞成功率则相对较低。\n\n这是一张表，阐述了不同类型NAT之间一般能否成功打洞\n\n| NAT类型 | FullCone | RestrictedCone | PortRestrictedCone | Symmetric |\n| --- | --- | --- | --- | --- |\n| FullCone | √ | √ | √ | √ |\n| RestrictedCone | √ | √ | √ | √ |\n| PortRestrictedCone | √ | √ | √ | X |\n| Symmetric | √ | √ | X | X |\n\n> 打洞的成功率由大至小依次为：FullCone > RestrictedCone > PortRestrictedCone > Symmetric。一般由打洞成功率高的NAT向打洞成功率低的NAT发起打洞请求，使弱势用户能够主动链接强势用户，便于弱势用户提前强势用户建立映射对。\n> \n> 受限锥-受限锥 受限端锥-受限端锥 需要任意一方在探测完后及时主动向对方发起链接，避免映射对被销毁。\n> \n> 对称型-端口受限锥型NAT之间的打洞成功率极低。(1/65535)。\n> \n> 而对称型NAT之间的打洞成功率几乎为0。(1/65535^2)\n\n[Ntop的N2N项目](https://github.com/ntop/n2n) 则是一个基于以上理论的开源项目，通过区分Edge(Client)和SuperNode(Server)的方式，方便了普通人的部署。\n\n由于映射对本身只能在内网用户主动向外请求时才能建立，故如何将获取到的映射对及时传递给对方，是N2N的关键。而SuperNode在此时起到了关键作用，SuperNode会记录下所有Edge的映射对并分享给对方，使得两个Edge能够及时知晓对方的映射对，从而建立联系。\n\n正常情况下，SuperNode并不参与数据传输，仅用于告知双方的映射对。然而，在双方NAT打洞成功率不高时，SuperNode也会回退为[TURN模式](https://zh.wikipedia.org/wiki/TURN)（即传统方式，利用服务器转发流量，篇幅所限不再赘述）。\n\nLinux用户可以直接下载[N2N的二进制文件](https://github.com/ntop/n2n/releases)，Windows与Mac用户则需要自行编译或使用第三方编译好的二进制文件。\n\n对于我在Windows上的使用，我通常用[ [灵工艺] 联机组网](https://nullcraft.org/d/39-%E5%85%8D%E8%B4%B9-%E7%81%B5%E5%B7%A5%E8%89%BA%E7%BD%91%E4%B8%8A%E9%82%BB%E5%B1%85-nullcraft-n2n)。其有GUI可以快捷配置，并且也很方便安装TAP适配器。~~主要是懒的敲命令行~~\n\n![](https://registry.npmmirror.com/chenyfan-os/0.0.0-r25/files/article/3.png)\n\n首先搭建N2N需要有一台拥有公网ip的服务器，然后在服务器上运行SuperNode。尽管SuperNode正常情况下不参与数据传输，但是N2N无法主动禁用TURN模式，故不建议公开部署SuperNode。\n\n搭建SuperNode可以直接安装N2N的二进制文件，配置文件存在`/etc/n2n/supernode.conf`\n\n```conf\n# /etc/n2n/supernode.conf\n-p=1234\n```\n\n运行`sudo systemctl start supernode`即可启动SuperNode，监听端口为1234。\n\n如果需要开机自启动，可以运行`sudo systemctl enable supernode`。\n\n如果当前运行环境（如Docker环境）不存在`systemctl`，可以自行下载N2N的项目源代码并自行编译：\n\n```shell\ngit clone https://github.com/ntop/n2n.git --depth=1\nbash ./autogen.sh\nbash ./configure\nmake\nmake install\n```\n\n然后采用`./supernode`的方式运行。\n\n针对Edge，可以直接运行二进制文件：\n\n```shell\nsudo edge -c mynetwork -k mysecretpass -a 192.168.100.1 -f -l supernode.ntop.org:7777\n```\n\n- `-c` 指定的链接组名，所有拥有相同链接组名的Edge会被视为同一组\n- `-k` 指定的链接组密码\n- `-a` 指定的内网ip\n- `-l` 指定SuperNode的ip和端口\n\n在另一台Edge上运行：\n\n```shell\nsudo edge -c mynetwork -k mysecretpass -a 192.168.100.2 -f -l supernode.ntop.org:7777\n```\n\n两台Edge将会自动建立链接，SuperNode会记录下两台Edge的映射对并分享给对方，使得两台Edge能够及时知晓对方的映射对，从而建立联系。\n\n可以尝试在内网ip为`192.168.100.1`的Edge上运行：\n\n```shell\nping 192.168.100.2\n```\n\n应当会有相应的回应。\n\n`Ctrl+C`退出后，可以看到类似的输出：\n\n```\n**********************************\n Packet stats:\n       TX P2P: 10 pkts\n       RX P2P: 10 pkts\n       TX Supernode: 4 pkts (2 broadcast)\n       RX Supernode: 2 pkts (1 broadcast)\n**********************************\n```\n\n其中`TX P2P`和`RX P2P`表示Edge之间的数据传输，`TX Supernode`和`RX Supernode`表示Edge与SuperNode的数据传输。\n\nSuperNode的数据包应该远小于Edge之间的数据包，因为SuperNode仅用于告知双方的映射对，以及刚开始来不及打洞时通过`TURN`的数据传输。\n\n如果经过一段时间后，`P2P`的数据包数仍然为0，说明N2N的打洞失败，应检查双方防火墙情况和NAT类型。\n\n> **Tips:**\n> \n> N2N的SuperNode默认允许了所有Edge的加入。尽管N2N官方有着[专门的鉴权方式](https://github.com/ntop/n2n/blob/dev/doc/Authentication.md)，但是配置及其麻烦，可以巧用[限制通讯组](https://github.com/ntop/n2n/blob/dev/doc/Communities.md)的方式，约定一个确定的通讯组名，限制只有拥有相同通讯组名的Edge才能加入。\n> \n> 修改`/etc/n2n/supernode.conf`，添加`-c`参数：\n>\n> ```conf\n> # /etc/n2n/supernode.conf\n> -p=1234\n> -c=/etc/n2n/communities.list\n> ```\n>\n> 然后在`/etc/n2n/communities.list`中添加通讯组名(允许采用正则表达式，一行一个)：\n>\n> ```\n> mynetwork\n> ```\n>\n> 重启SuperNode `sudo systemctl restart supernode` 即可生效。\n\n## How to Transform Home networks to get FullCone NAT\n\n> 如果你已经拥有了公网IPV4，那么请直接略过这一节。\n\n### Disable Firewall\n\n控制面板进入`高级安全 Windows Defender 防火墙`，在入站规则添加规则，**允许**所有端口的`UDP`。在出站规则中也如法炮制。\n\n> 为了安全性你也可以限定端口范围，但是这样会降低打洞成功率。\n>\n> 你不需要允许TCP协议，因为N2N默认采用的STUN探测协议为UDP。\n\n![](https://registry.npmmirror.com/chenyfan-os/0.0.0-r25/files/article/4.png)\n\n![](https://registry.npmmirror.com/chenyfan-os/0.0.0-r25/files/article/5.png)\n\n![](https://registry.npmmirror.com/chenyfan-os/0.0.0-r25/files/article/6.png)\n\n![](https://registry.npmmirror.com/chenyfan-os/0.0.0-r25/files/article/7.png)\n\n如果你使用的是第三方防火墙，也请关闭防火墙或者添加规则。\n\n### Enable DMZ host\n\n[DMZ技术](https://zh.wikipedia.org/zh-cn/DMZ)，Demilitarized Zone的缩写，是一种网络安全技术，用于将内部网络与外部网络隔离开来。而对于家庭网络而言，DMZ主机的则是路由器将所有端口的流量都转发到这台主机上。\n\n> 在严格意义上，DMZ与内部网络是隔离的，但是在家庭网络中，DMZ主机仍然可以访问内网，而内网用户也可以访问DMZ主机。\n\n在路由器设置中，找到DMZ主机设置，将你的电脑ip设置为DMZ主机。\n\n首先查询自己电脑的内网ip地址：\n\n```shell\nipconfig /all\n```\n\n![](https://registry.npmmirror.com/chenyfan-os/0.0.0-r25/files/article/8.png)\n\n记下地址为`192.168.31.215`\n\n以我的小米路由器为例，登录路由器后台，找到`高级设置`-`端口转发`-`DMZ主机`，将地址填入：\n\n![](https://registry.npmmirror.com/chenyfan-os/0.0.0-r25/files/article/9.png)\n\n保存即可。\n\n> 如果你的路由器不支持DMZ主机设置，可以尝试将你的电脑设置为静态ip，并将所有的UDP端口转发到你的电脑上。\n\n\n### Change to Bridge\n\n目前的家庭网络通常是 光纤入户 -> 运营商提供的智能网关 -> 用户路由器 -> 用户电脑的结构。其中智能网关通常是光猫+路由器+AP的缝合怪。按照大部分地区的安装指导，光猫默认会工作在NAT模式下，以便于用户能够直接使用，而无需拨号。\n\n然而，大部分光猫NAT的策略都默认设置为对称性NAT，即使光猫拥有DMZ主机设置，最终NAT类型也是对称性NAT。\n\n因此，我们需要将智慧网关设置为桥接模式（工作在仅光猫状态），将路由器设置为拨号上网，再在路由器上设置DMZ主机。\n\n> 是不是看起来很怪？事实上大部分家庭网络都是FullCone NAT，但是由于智慧网关的NAT策略，使得家庭网络的NAT类型变为了对称性NAT。\n\n将智慧网关设置为桥接状态，通常需要获取光猫的超级管理员密码，然后删除原有的配置，新建新的桥接配置，并在下一级的路由器上设置拨号上网。\n\n由于篇幅所限，这里不再赘述具体的操作步骤。光猫的具体破解方式各异，可以尝试自行搜索`XXX-XX型号光猫改桥接`。\n\n---\n\n通常来讲，设置好桥接 - 设置DMZ主机 - 关闭防火墙后，你的家庭网络应该已经变为了FullCone NAT。此时不妨利用pystun3测试一下你的NAT类型。如果已经为FullCone，那么恭喜你。如果没有，那么你当地的运营商很可能对网络进行了限制。\n\n## So, why I prefer FullCone NAT\n\n第一个原因是，相对于公网IPV4，FullCone的改造更为廉价和安全。在大多数地区，公网IPV4的价格昂贵，而且公网IPV4的暴露会使得内网用户的安全性大大降低。~~此外，移动运营商由于本身v4资源匮乏，绝大多数地区已经不再提供公网IPV4~~\n\n此外，相较于IPV6，传统的IPV4的网络设备更为成熟，出门在外想要连回家里的网络，如果没有IPV6，那么还得要绕道服务器转发。\n\n相对于传统服务器内网穿透，直接点对点链接的优势无疑是巨大的，最终双方的访问质量仅取决于双方的网络质量，而不再受到服务器的限制。（比如我在外就可以直接跑满家庭上行100M，而不是服务器龟速5M上行，这使得远程串流游戏成为了可能）\n\n回到文章的刚开始，由于我拥有了FullCone NAT，当MC服务器启动在我电脑后，通过N2N软件，朋友的客户端能够直接链接到我的电脑上。由于我们过年回家都在台州，相互之间直接连接的质量也相较于内网穿透的质量高上不少。\n\n> 尽管N2N不需要FullCone也有一定概率能够打洞，但是FullCone就是爽\n\n然而除此之外，如果对FullCone网络进行恰当的改造，那么我就能在无法拥有公网ip（毕竟是移动）的情况下，享受公网ip的待遇。访问效果上等同于拥有了一组公网IP:端口。\n\n### Export My Server to Public Internet\n\n先前我的脚本已经证明，FullCone网络在通过恰当的方式打洞后，能够直接将内网ip暴露在公网上。事实上，Github已经有类似的项目能够探测FullCone NAT的映射对的程序，例如[NATMAP](https://github.com/heiher/natmap) 和 [Natter](https://github.com/MikeWang000000/Natter)。\n\n其中，NATMAP基于C++，暂时还不支持Windows。而Natter则是基于Python的，支持Windows（但截至本文发稿时Windows上UDP穿透仍存在严重的问题），也支持流量转发（由于探测需要临时占用端口，而部分程序无法解除端口占用，故可以新开一个随机端口用于探测，然后将探测端口流量转发到目标端口即可）。\n\n事实上，你可以利用NATMAP或Natter探测到的映射对记录映射对，并通过其他简易的内网穿透或者定时上传到公开网站的方式，实现一个简单的DDNS。\n\n> 另一方面，DNS记录中存在名为SRV的记录类型，可以指定端口。如果你拥有一个域名，那么你可以通过SRV记录将你的映射对共享出去。\n>\n> 与DDNS技术相比，通过FullCone打洞仅仅多了一个端口的记录。\n\n> 此外，截至本文发稿时，Natter“固定”映射对的效果尚不如NATMAP，在关闭程序后映射对可能会发生改变，但是Natter的配置更加方便，也支持流量转发。\n\n通过这种方式，我已经成功将我的服务器Wireguard入口暴露到了公网上，至此，我可以在不购买公网IPV4、无IPV6的情况下，在任何地方通过我的服务器访问到我的家庭网络。\n\n至于其他的RDP、SSH等服务，也可以通过类似的方式实现。不过建议还是只暴露Wireguard入口，然后通过Wireguard内网穿透到其他服务。~~毕竟安全第一~~\n\n### Get A HighID in P2P download\n\n在电驴下载中，存在这`LowID`和`HighID`的概念。`LowID`是指没有公网IPV4的用户，而`HighID`则是指拥有公网的用户。两个`LowID`之间无法直接链接，但是`HighID`可以直接链接到`LowID`和`HighID`。\n\n在其他P2P下载中，也存在类似的概念。放到PT下载中，拥有一个`LowID`的用户，相对于`HighID`用户而言，下载速度会大大降低。同时，`LowID`用户在做种时也无法主动链接到其他`LowID`用户，从而影响了共享效果，在PT上传中很难抢到上传流量。\n\n然而，通过FullCone NAT，我可以将我的PT客户端的端口暴露在公网上，从而获得了`HighID`。但是在这其中存在一个问题，映射对中内网端口和外网端口通常是不一致的，而PT客户端向Tracker服务器报告的端口是内网端口，外网用户无法用（公网ip:内网端口）访问到我的PT客户端。\n\n因此，需要先随机探测一个映射对，记录（内网ip:内网随机端口）和（公网ip:外网端口）的对应关系，并新建一个转发，将（内网ip:内网随机端口）的流量转发到（内网ip:外网端口），并通过BT客户端的API修改BT程序监听端口为外网端口。通过这种方式，使BT客户端向Tracker服务器报告的端口为外网端口，从而获得了`HighID`。\n\n[这是我之前不知道在那个论坛抄下来的脚本](https://gist.github.com/ChenYFan/8b5ba92875a195a992c7d451490971e4)，可利用natmap或natter的script功能自动修改BT客户端的监听端口并转发流量，出处已不可考。\n\n---\n\n到这里为止，FullCone NAT好像已经变得完美无瑕，它拥有着相对于公网v4极高的性价比，并且有着丰富的DIY内容。这篇文章在这里应该已经结束了\n\n...吗？\n\n## It is Hard to Get a FullCone NAT\n\n你并没有那么容易获得全锥网络。由于大部分运营商的光猫已经被逐步替换为了智能网关，破解智能网关本身就具有这相当高的难度。\n\n> 我知道你想说什么，花了150的租金，拿了个什么都缝合了、什么都没缝合好的电子垃圾。wifi只有2.4G不支持5G，不支持在NAT中下发公网IPV6，大部分功能被运营商锁定不让你用，甚至还有[远控后门](https://v2ex.com/t/952671)。\n\n此外，不像我手上的移动H3-2se智能网关有着开启telnet的漏洞，大部分智能网关想要获取超管密码都极为困难，想要破解获得密码还得根据型号来选择方式。部分机型还需要替换备份包的方式刷机，稍有不慎就会出现意外，破解的难度极高。\n\n另一方面，运营商显然是不希望用户改为桥接模式的。\n\n首先，[按照知乎上的普遍说法](https://www.zhihu.com/question/587820301)，改桥接意味着运营商将丢失对光猫的远程控制，一旦用户家庭网络出现问题，则无法远程解决，需要安装师傅上门，浪费人力物力。\n\n> 事实上，相对于智能网关即插即用的特性，改为桥接需要用户在路由器或者在电脑上拨号。这对于不了解网络的用户来说是一件很麻烦的事情，免不了请人帮忙安装。\n\n其次，桥接模式意味着用户可以自行选择路由器，而不再受限于运营商提供的智能网关，运营商则无法在终端网络上提供额外的审查能力。\n\n此外，一旦改为桥接，[部分地区的运营商还会降速](https://www.v2ex.com/t/887345)，（尽管不排除光猫性能羸弱可能性）。\n\n最重要的原因是，运营商它怕你占用了大量的**上行**带宽...\n\n### ISP is Afraid of PCDN\n\nPCDN，Peer-to-Peer Content Delivery Network，即点对点内容分发网络。\n\n这个名词在普通网络中并不常用，但国内诸多互联网厂商对此并不陌生。由于大陆政策的商宽补贴家宽的特性，相较于国外家宽的价格，国内家宽的价格极为便宜。\n\n然而如此一来，宽带成本压力就转嫁到了商宽上，云服务厂商接入ISP的价格极其昂贵（国内网盘业务难以发展的原因之一）。类似视频分发等业务，如果全部由云服务厂商提供，那么运营成本将会难以负担。\n\n于是各大国内服务商就走起了歪路，PCDN这一邪门技术便应运而生。PCDN的核心思想是，用户之间互相分享资源，从而减轻服务器的存储压力和带宽压力。\n\n通常来讲，用户可以主动作为pcdn节点共享带宽，从而向服务商赚取少量佣金。服务商只要付出极少成本，就能够获得遍布在广大用户间海量存储和带宽资源。先前百度网盘试图开放`闲置宽带优化计划`，也是PCDN的一种。~~当然你白开一年PCDN换取到的奖励也是微乎其微的~~\n\n> 服务商的打洞方式当然也包括N2N打洞。事实上服务商的客户端程序打洞的方式可能更多更狠，本文仅涉猎了其中一种方式。\n\n然而，[有一些软件可能会自己偷偷摸摸跑PCDN](https://www.v2ex.com/t/945773)，用户很大概率是无感的（毕竟XX视频、XX音乐、XX网盘客户端上传都是限速的，以避免大量占用资源而被察觉）。~~太离谱了还是会被发现的~~\n\n自然，运营商是极其不乐意的，PCDN固然**降低了服务商的压力**，但这些压力分毫不少的转移到了运营商的头上，运营商从服务商**收取的钱变少了**，还**承担了相同（甚至更多的）带宽压力**。\n\n但是，运营商的骨干网络通常没有做单独的限制，通过改造骨干网络来限制PCDN显得不太现实。因此运营商只能在终端网络上下手。而在智能光猫内植入限制，是最为方便的方式。\n\n> 这就是为什么当我们解除了终端智能光猫的限制后，NAT类型通常都还原回了FullCone。\n\n> 但是，部分地区运营商检测到用户如果在偷跑PCDN（不管是不是故意的）或者长时间大规模占用上行带宽，会针对性地对用户上行进行限速，或者将用户NAT降级为对称性NAT。\n\n一旦开启桥接，诸多互联网厂商软件会直接开始吸血家宽。由于国内宽带通常计费方式是包年计带宽，不计流量，因此用户可能完全不会察觉到PCDN的开启，但运营商则会为此承担更多的带宽压力。\n\n> 此外，运营商对BT等P2P下载也是深恶痛绝的，但是彻底根除显得并不现实，因此运营商只能通过劣化互联质量降低上传宽带的占用。\n\n---\n\nNAT的发明极大减缓了全球IPV4地址枯竭的难题，它允许了多个网络设备共享一个公网IPV4地址。然而现如今，IPV6的时代已经到来，NAT却成为了IPV6发展的障碍。究其原因，是因为NAT设立之初并没有考虑计划淘汰 - 它可以一直永远的工作下去。\n\n> 并且，NAT通常也用于隔离内部网络和外网，即使是在IPV6中也会存在NATv6确保内网用户的安全性。\n\n然而，由于NAT的设计阻碍了不同内部网络双方的直接通讯 - 即使双方并不想在内部网络，但由于IPV4的枯竭，他们不得不用，这使得类似于物联网、智能汽车等需要**万物互联**新兴技术受到了阻碍。即使物联网设备用上了IPV6 - 你能确保走出门外，随便接入一个wifi都有IPV6吗？\n\n一个听起来令人发笑的事实是，8年前的无线路由器依旧在我家工作的很好 - 它支持802.11ac(5GHz)，提供了和外网带宽匹配的无线带宽速率。**它只是不支持IPV6**。\n\n我有必要换它吗？我不认为，因为在我实际上网过程中，纯IPV6的网站并不多；家里人也不需要所谓的IPV6，因为他们的需求仅仅是看视频和上网购物；家里设备也不需要IPV6，因为这种小型家庭监控、冰箱、扫地机器人通常是通过物联网卡上网的，即使连接WIFI，也是通过云服务商提供的服务来访问的。\n\n它只要能正常工作，**这就够了**。\n\n现在我想在我家放一台NAS，我的需求是能在离开家之后随时随地访问这台NAS。那么，纯IPV6也不能满足我的需求，因为我不能保证我在外面的网络环境拥有IPV6 - 是的，因为不支持IPV6的网络设施依旧能在纯IPV4的网络环境下工作，为什么一定要淘汰它呢？\n\n纵然国家大力支持发展IPV6，但是在实际民用网络应用中，IPV6的普及率依旧很低，终端设备（家庭网关、无线路由器）的淘汰问题成为了IPV6普及的最大障碍。此外，部分地区运营商甚至把IPV6与公网IPV4对立，声称为了[普及IPV6而开始对公网IPV4收费](https://www.189.cn/sc/sy_ycgg/118104.html)，并借机[利用NAT4444实现假公网V4](https://www.v2ex.com/t/875867)。\n\n![](https://registry.npmmirror.com/chenyfan-os/0.0.0-r25/files/article/2.jpg)\n\n> 与其花399购买一个静态FullCone网络，不如免费白嫖动态FullCone网络\n\n另外，正如我之前提到的，家庭网络绝大多都是FullConeNAT，如果有足够的折腾精神，改造光猫对我而言并不困难。\n\n事实上，我现在在自己的NAS上就同时部署了两种穿透方案，一种是FRP，另一种是用利用NATMAP探测并将探测到的映射记录同步到DNS的SRV记录上。通过这种方式，我可以在任何地方直接用Wireguard连回家，除非遇到故障才会去用FRP。\n\n---\n\n这就是FullCone NAT，它一直存在于我们生活中，并且仍具有极高的利用价值。如果能够合理的利用它，我想节省下一笔关于公网IPV4的费用，也不是不可能的。\n\n只是可惜，在如今运营商政策的收紧、光猫破解变得越来越难的趋势下，FullCone NAT的普及率将只会变得越来越低。\n\n在写下本篇文章的最后一段时，我想等到数年后IPV6彻底普及，会不会有人看完这篇文章会嘲笑，在2024年的时候，还有一个傻子拒绝公网IPV6，还在尝试使用已经宣告缓刑的IPV4进行“万物互联”呢？\n\n这里是CyanFalse的小站，一个小小的年更博客，感谢您的阅读。\n\n\n\n","tags":["黑科技","网络","NAT","内网穿透"],"categories":["随心扯"]},{"title":"笔记本安装Ubuntu+Win10双系统疑难杂症记录","url":"/p/e73f73cf.html","content":"\n入手一台鸡哥笔记本，折腾双系统，记录一下关于AX101网卡和N卡驱动引起的各种问题。\n\n<!-- more -->\n\n---\n\n芜湖！两朝荒芜，今日割草！\n\n手中4699入了一台机械革命极光Z的笔记本，i5-12450H 32G+1T 3050 作为一台中等级别的游戏本还是比较划算的。尽管12450为残血，3050为甜品卡，但是对于我这种不玩大作游戏的人来说，性能还是足够的。\n\n本着折腾的心态，尝试给这台机子加装上ubuntu。因为有着对服务器硬盘装双系统的经验，本以为装机过程是轻松加愉快，没想到扯出这么多问题。\n\n## 安装\n\n首先现有系统关闭Bitlocker（不然之后有够你受的）\n\n```Shell\nmanage-bde -off C:\nmanage-bde -off D:\n```\n\n前往 计算机管理-磁盘管理 压缩卷\n将D盘割出131072MB(128GB) 作为闲置卷，不格式化 不挂载\n\n![割盘操作](https://registry.npmmirror.com/chenyfan-os/0.0.0-r26/files/img%20(6).png)\n\n从[Ubuntu Dekstop Download](https://cn.ubuntu.com/desktop)下载22.04LTS版本\n因为本来是打算硬盘安装，于是将压出来的128GB中割了8GB作为安装盘，格式化为exFAT或FAT32（UEFI无法从NTFS引导），直接将iso解压到里头。\n\n重启，鸡哥的机子通常是按F2进入BIOS。\n\n![BIOS](https://registry.npmmirror.com/chenyfan-os/0.0.0-r26/files/img%20(1).jpg)\n\n进入BIOS后优先关闭SecureBoot，然后尝试改变引导的时候才发现鸡哥bios太老了，没有`Boot From File`选项。\n\n![SecureBoot](https://registry.npmmirror.com/chenyfan-os/0.0.0-r26/files/img%20(2).jpg)\n\n满头大~~汉~~汗翻了个8GB的U盘（还不支持USB3.0的古董U）回来，一套格式化+写入。\n\n由于鸡哥的引导优先级中`USB Device`是排在`NVME Device`上的，所以在插入u盘的时候优先从u盘引导，进入熟悉的Ubuntu加载页面。\n\n~~然后被USB2.0的20MB/s写入卡了三分钟~~\n\n修改镜像为tuna源，将割出来的120GB分区给挂载到`/`下。五分钟不到安装完毕。\n\n安装完毕后别急着直接关机，先修改grub引导为console再重启。\n\n因为据我安装服务器的经验来谈，grub启动时若加载N卡驱动则由grub引导的windows一定会出现花屏问题。\n\n`Ctrl+Alt+T`打开终端，`nano /etc/default/grub.cfg`修改grub配置文件：\n\n```cfg\nGRUB_TERMINAL=console\n```\n\n加入后保存退出,`update-grub`更新\n\n`reboot`重启时，机子关机关到一半突然卡住，tty无法切换，CAD连招也失效，推测应该是N卡驱动问题，长按电源键强制关机。\n\n## 将启动引导改为Grub\n\nWindows默认是不会识别Ubuntu引导的，而修改windows引导过于麻烦。不如直接将默认引导改为grub，由grub启动windows。\n\n鸡哥由于bios过老，修改方式比较脑瘫，从`UEFI NVME Drive BBS Priorities`进入，将第一个启动项改为ubuntu即可。\n\n![Boot](https://registry.npmmirror.com/chenyfan-os/0.0.0-r26/files/img%20(3).jpg)\n![Boot](https://registry.npmmirror.com/chenyfan-os/0.0.0-r26/files/img%20(4).jpg)\n\n\n重启，能正常进入grub引导，记下第三个为Windows Boot Manager（id为2），尝试分别进入Windows和ubuntu均无太大问题\n\n![SecureBoot](https://registry.npmmirror.com/chenyfan-os/0.0.0-r26/files/img%20(5).jpg)\n\n## 解决蛋疼的无线网卡问题\n\n进入ubuntu的时候，尝试打开浏览器却提示无网络链接，心里不由得咯噔一下。\n\n好在手头还有一个已经破解了的中兴微随身wifi，尝试插入能够被识别为有线网卡，利用随身wifi全功能后台中的wifi中转功能连上了家中路由器。\n\n![SecureBoot](https://registry.npmmirror.com/chenyfan-os/0.0.0-r26/files/img%20(1).png)\n\n略微浏览之后发现是AX101网卡驱动没装，于是满怀信心地前往intel linux驱动下载，结果却发现，只有20系，没有10系的网卡驱动。\n\n~~这就肥肠、肥肠抽象了~~\n\nAX101卡是Intel wifi6系列卡中最~~垃圾~~入门的一款，仅有600Mbps理论速率。虽然对于我来说已经完全足够需求（毕竟我在现实中就没连过哪个网速超过500Mbps的网络）了，但是连官网都没有linux驱动支持，心态，不由得发生了一内内变化。\n\n百度上查了一圈，基本文不对题，最后在知乎站内搜索找到了[解决方案](https://www.zhihu.com/question/586002680/answer/3128720014)，但在系统内核安装的时候又出现了亿点点小坑。\n\n首先前往[内核下载](https://kernel.ubuntu.com/~kernel-ppa/mainline/)，选择`6.1.15`\n\n> 尽管是**及以上**，但是实测6.2版本会error，其余更高的未测试\n\n![SecureBoot](https://registry.npmmirror.com/chenyfan-os/0.0.0-r26/files/img%20(7).png)\n\n将红框内的内核全部下载，然后\n\n```shell\ndpkg -i *.deb\nupdate-grub\n```\n\n重启，使6.1.15内核加载到系统中。\n\n但是如果你是从更高的版本降下来的话，那你还要考虑卸载高版本。\n\n```shell\ndpkg --list | grep linux-image\ndpkg --list | grep linux-headers\n```\n\n通过上述命令列出所有的image和header，然后用`apt-get purge`命令清除\n\n当你尝试清除最高版本的kernel时，系统可能会建议你中断当前操作，因为可能会造成系统不稳定。这时候选择`No`(不Abort卸载过程)，完成卸载后`reboot`重启。重新进入后输入 `uname -r`则会发现系统内核已被降级到6.1.15。\n\n`apt install git`，安装git后，先安装makedeb：\n\n```shell\nbash -ci \"$(wget -qO - 'https://shlink.makedeb.org/install')\"\n```\n\n克隆并打包`iwlwifi-ax101-dkms`项目：\n\n```shell\ngit clone 'https://mpr.makedeb.org/iwlwifi-ax101-dkms'\ncd iwlwifi-ax101-dkms/\nmakedeb -si\n```\n\n注意不要以root身份运行。完成后会提示提权，此时切换到root安装驱动包：\n\n```shell\ndpkg -i iwlwifi-ax101-dkms_6.1.15-2_amd64.deb\n```\n\n重启后wifi应当可用。\n\n![SecureBoot](https://registry.npmmirror.com/chenyfan-os/0.0.0-r26/files/img%20(2).png)\n\n## Ubuntu关机时假死 - N卡驱动问题\n\n由于之前没有安装N卡驱动，导致电脑关机时会突然卡在徽标页面，加载圈也不转，~~所以之前的关机一直都是强制关机~~\n\n由于不太喜欢自带的额外驱动程序安装，所以还是用传统的官网驱动。\n\n[老黄家走一趟](https://www.nvidia.cn/Download/index.aspx)，下载下来一个run文件。此时要关闭X server在tty中使用\n\n`Ctrl+Alt+F3`切换到tty模式，输入账户密码登录。\n\n首先要清除ubuntu安装中有可能打上去的莫名其妙的驱动，以及安装必要的库\n\n```shell\napt-get update\napt-get remove --purge nvidia*\napt-get install dkms build-essential linux-headers-generic\n```\n\n然后拉黑nouveau，`nano /etc/modprobe.d/blacklist-nouveau.conf`输入以下内容\n\n```\nblacklist nouveau\nblacklist lbm-nouveau\noptions nouveau modeset=0\nalias nouveau off\nalias lbm-nouveau off\n```\n\n并禁用nouveau：\n\n```shell\necho options nouveau modeset=0 | sudo tee -a /etc/modprobe.d/nouveau-kms.conf\nupdate-initramfs -u\n```\n\n重启，同样进入tty模式，先暂停图形服务\n\n```shell\nservice gdm stop #or lightdm\n```\n\n然后懒人`bash *.run`开始安装。\n\n### 题外话：一不小心用了Nvidia驱动的XConf导致进不去系统怎么办\n\n多半是当老黄问你要不要换成由Nvidia驱动X服务的时候手欠选了Yes(然而这里默认是no)\n\n```\nWould you like to run the nvidia-xconfig utility to automatically update your X \nconfiguration file so that the NVIDIA X driver will be used when you restart X? \nAny pre-existing X configuration file will be backed up.\nYes   No\n```\n\n~~你看老黄都知道大概率会出问题还给你贴心备份了来着~~\n\n此时别瞎几把听网上说的卸载n卡驱动，重启进入grub时，选择recovery mode，root模式，恢复被老黄改过的XConf即可\n\n```shell\ncd /etc/X11/\nrm -rf xorg.conf\nmv nvidia-xconfig-original.conf  xorg.conf\n```\n\n重启即可，关机卡死问题也被成功解决\n\n### 题外话：更新内核导致掉驱动怎么解决\n\n老黄在安装驱动的时候会问你要不要安装dkms，在内核更新的时候自动更新。\n\n没有选yes问题也不大，先`apt install dkms`，\n\n再看一眼当前版本`ls -l /usr/src/`\n\n手动安装`dkms install -m nvidia -v 5xx.xx.xxx`\n\n## 安装蓝牙驱动\n\n这个还算是小问题，首先`dmesg`瞅一眼哪报错了。\n\n![dmesg](https://registry.npmmirror.com/chenyfan-os/0.0.0-r26/files/img%20(3).png)\n\n提示无法启动1050蓝牙驱动。\n\n这个时候我第一时间想到的是安装`bluez`这玩意，直到我看到了[Ubuntu22.04 在零刻EQ12 安装蓝牙无法启动问题](https://zhuanlan.zhihu.com/p/628772433)，他告诉我，可以直接复制一份同系列的intel驱动。\n\n咳，虽然比较阴间，不过对我这台鸡哥也是可行的。\n\n![bluetooth](https://registry.npmmirror.com/chenyfan-os/0.0.0-r26/files/img%20(4).png)\n\n\n## 其他一些小优化\n\n### 系统默认进入Windows\n\n已安装Windows后再安装ubuntu，grub的默认启动会优先进入ubuntu。\n\n修改`/etc/default/grub.cfg`，将`GRUB_DEFAULT`改为`Windows Boot Manager`的id（正常情况下为2）\n\n```shell\nGRUB_DEFAULT=2\n```\n\n### Ubuntu下挂载Windows NTFS盘\n\n安装依赖`sudo apt install nfs-kernel-server fuse`\n\n先`fdisk -l`瞅一眼自己的盘在哪个分区，然后用`mount`挂载\n\n```shell\nmount -t ntfs /dev/sdxx /Windows/D\n```\n\n`/Windows/D`即windows下D盘内容，建议用chmod提权写入。\n\n\n至于Windows下挂载ext4，用ext2fsd险些给我盘挂坏...win下挂载很麻烦，又因为是同一块盘没法用wsl挂载。windows下挂载还是先晾着有空再来解决。\n\n### Ubuntu与Windows时间差\n\n老生长谈的问题，22.04可以直接强制改为本地时间而避免时区错误`timedatectl set-local-rtc 1 --adjust-system-clock`\n\n\n---\n\n除个草，浇浇水(\n截个图，留个纪念\n\n![ALL](https://registry.npmmirror.com/chenyfan-os/0.0.0-r26/files/img%20(5).png)\n\n","tags":["双系统","Ubuntu","驱动","疑难杂症"],"categories":["解疑惑"]},{"title":"SpeedUp!使用黑科技为你的网站提速","url":"/p/d3c51290.html","content":"\n实战，利用黑科技ServiceWorker提速你的网站。\n\n<!--more-->\n\n---\n\n\n> 本文所标记的内容，大多是直接复制粘贴即可实现的。但依然会存在这和您的服务存在冲突这一情况。请阅读上一篇基础文章[欲善其事，必利其器 - 论如何善用ServiceWorker](/p/c0af86bb.html)进行合理的修改。\n\n\n我们简单的列一下表，这是我们加速清单：\n\n\n- [分离资源，静态加速](#前端竞速CDN)\n- [加速主网页](#全站NPM静态化)\n- [调剂响应](#调剂响应)\n- [首屏加速](#优化首屏)\n\n# 前端竞速CDN\n\n最传统的网页加载，其静态资源一旦独立是直接放在同域服务器下的。\n\n不过后来，为了减少主服务器开销，我们通常将静态资分离至其他面向用户加载比较快的节点，以减少主服务器开销，提升网页加载速度。\n\n现在，各种公益cdn服务蓬勃生长，其节点通常是全球部署，并且对各个国家/地区做了优化，使用公益cdn，他的质量和可用性是远远大于自己部署的。\n\n在一个网页加载中，主网页只提供一个html（你所看的网页其大小约`15kb`），而流量开销巨头是静态资源（只论js，本页大约`800kb`）。我们对一个网站的加速，第一步就应当从静态加速做起。\n\n对于加速存储的选择，通常市面上有三种主流加速`cdnjs`/`npm`/`gh`。而在这其中，对于个人而言，我还是推崇`npm`，这在接下来对于竞速节点的选择就多了起来。\n\n对于加速节点的选择，从mainland角度来讲，首先你要遵循一个普世结论：`不要用跨国节点`。本身China国度就有个奇葩规定，没有ICP备案许可就不得在mainland开展网站服务。这使得大部分本应该分散在边缘末端的流量全压到了国际出口的汇聚层。你再引导他们去海外拉资源，凑过去挤热闹，其稳定性和速率完全无法保证，这在生产环境使用无异于自杀。这里提一嘴jsdelivr，备案掉了，节点迁出中国了，那你面向国内的网站早就可以切了。使用fastly，联通和电信晚上ntt几乎堵到妈都不认识，能连上就是奇迹。除非你真的不在意加速，也不在意资源能不能正常加载，在面向mainland的生产环境里还坚持jsd就是愚不可及的行为。\n\n当然，在这里我还是推崇黑科技`ServiceWorker`，它可以利用`Promise.any`，并发数个请求至不同的cdn节点，提升前端资源加载。而借助于强大的js引擎，其在本地处理的效率奇高，性能折损几乎不计。\n\n在这之前，我们定义一个`lfetch`，它的作用是对`urls`这个数组里的所有网址发起并发请求，并且在任意一个节点返回正常值时**打断**其余请求，避免流量浪费。\n\n```js\nconst lfetch = async (urls, url) => {\n    let controller = new AbortController(); //针对此次请求新建一个AbortController,用于打断并发的其余请求\n    const PauseProgress = async (res) => {\n        //这个函数的作用时阻塞响应,直到主体被完整下载,避免被提前打断\n        return new Response(await (res).arrayBuffer(), { status: res.status, headers: res.headers });\n    };\n    if (!Promise.any) { //Polyfill,避免Promise.any不存在,无需关注\n        Promise.any = function (promises) {\n            return new Promise((resolve, reject) => {\n                promises = Array.isArray(promises) ? promises : []\n                let len = promises.length\n                let errs = []\n                if (len === 0) return reject(new AggregateError('All promises were rejected'))\n                promises.forEach((promise) => {\n                    promise.then(value => {\n                        resolve(value)\n                    }, err => {\n                        len--\n                        errs.push(err)\n                        if (len === 0) {\n                            reject(new AggregateError(errs))\n                        }\n                    })\n                })\n            })\n        }\n    }\n    return Promise.any(urls.map(urls => {//并发请求\n        return new Promise((resolve, reject) => {\n            fetch(urls, {\n                signal: controller.signal//设置打断点\n            })\n                .then(PauseProgress)//阻塞当前响应直到下载完成\n                .then(res => {\n                    if (res.status == 200) {\n                        controller.abort()//打断其余响应(同时也打断了自己的,但本身自己已下载完成,打断无效)\n                        resolve(res)//返回\n                    } else {\n                        reject(res)\n                    }\n                })\n        })\n    }))\n}\n```\n\n在这其中，有一个难点：`fetch`返回的时状态而非内容。\n即当`fetch`的`Promise resolve`时，它是已经获得了响应，但此时内容还没下载，提前打断会导致无法返回。这是`PauseProgress`作用。\n\n之后我们考虑静态资源加速。这时候用npm的好处就体现出来了，不仅镜像多，其格式也还算固定。\n\n\n> 注意，此方法是以流量换速度的方式进行的，虽然在任何一个节点返回正确内容后会打断其余请求，但依然会造成不可避免的流量消耗(+~20%)。如果你面向的是手机流量用户，请三思而后行！\n\n> 此代码与[freecdn-js](https://github.com/EtherDream/freecdn-js)核心功能相似，但实现方法并不同，并且完全支持动态网页。\n\n例如jquery，你可以这样加速：\n\n```\n原始地址:\nhttps://cdn.jsdelivr.net/npm/jquery@3.6.0\n各类镜像：\nhttps://fastly.jsdelivr.net/npm/jquery@3.6.0\nhttps://gcore.jsdelivr.net/npm/jquery@3.6.0\nhttps://unpkg.com/jquery@3.6.0\nhttps://unpkg.zhimg.com/jquery@3.6.0 #回源有问题\nhttps://unpkg.com/jquery@3.6.0\nhttps://npm.elemecdn.com/jquery@3.6.0\nhttps://npm.sourcegcdn.com/jquery@3.6.0 #滥用封仓库\nhttps://cdn1.tianli0.top/jquery@3.6.0 #滥用封仓库\n```\n\n我们可以简单搓一个sw小脚本完成前端加速：\n\n\n<details class=\"about\">\n    <summary>ServiceWorker完整代码：</summary>\n   <details>\n    <summary>我已经很详细的看了上面的阐述，并且我不会直接照搬</summary>\n\n```js\nconst CACHE_NAME = 'ICDNCache';\nlet cachelist = [];\nself.addEventListener('install', async function (installEvent) {\n    self.skipWaiting();\n    installEvent.waitUntil(\n        caches.open(CACHE_NAME)\n            .then(function (cache) {\n                console.log('Opened cache');\n                return cache.addAll(cachelist);\n            })\n    );\n});\nself.addEventListener('fetch', async event => {\n    try {\n        event.respondWith(handle(event.request))\n    } catch (msg) {\n        event.respondWith(handleerr(event.request, msg))\n    }\n});\nconst handleerr = async (req, msg) => {\n    return new Response(`<h1>CDN分流器遇到了致命错误</h1>\n    <b>${msg}</b>`, { headers: { \"content-type\": \"text/html; charset=utf-8\" } })\n}\nlet cdn = {//镜像列表\n    \"gh\": {\n        jsdelivr: {\n            \"url\": \"https://cdn.jsdelivr.net/gh\"\n        },\n        jsdelivr_fastly: {\n            \"url\": \"https://fastly.jsdelivr.net/gh\"\n        },\n        jsdelivr_gcore: {\n            \"url\": \"https://gcore.jsdelivr.net/gh\"\n        }\n    },\n    \"combine\": {\n        jsdelivr: {\n            \"url\": \"https://cdn.jsdelivr.net/combine\"\n        },\n        jsdelivr_fastly: {\n            \"url\": \"https://fastly.jsdelivr.net/combine\"\n        },\n        jsdelivr_gcore: {\n            \"url\": \"https://gcore.jsdelivr.net/combine\"\n        }\n    },\n    \"npm\": {\n        eleme: {\n            \"url\": \"https://npm.elemecdn.com\"\n        },\n        jsdelivr: {\n            \"url\": \"https://cdn.jsdelivr.net/npm\"\n        },\n        zhimg: {\n            \"url\": \"https://unpkg.zhimg.com\"\n        },\n        unpkg: {\n            \"url\": \"https://unpkg.com\"\n        },\n        bdstatic: {\n            \"url\": \"https://code.bdstatic.com/npm\"\n        },\n        tianli: {\n            \"url\": \"https://cdn1.tianli0.top/npm\"\n        },\n        sourcegcdn: {\n            \"url\": \"https://npm.sourcegcdn.com/npm\"\n        }\n\n    }\n}\n//主控函数\nconst handle = async function (req) {\n    const urlStr = req.url\n    const domain = (urlStr.split('/'))[2]\n    let urls = []\n    for (let i in cdn) {\n        for (let j in cdn[i]) {\n            if (domain == cdn[i][j].url.split('https://')[1].split('/')[0] && urlStr.match(cdn[i][j].url)) {\n                urls = []\n                for (let k in cdn[i]) {\n                    urls.push(urlStr.replace(cdn[i][j].url, cdn[i][k].url))\n                }\n                if (urlStr.indexOf('@latest/') > -1) {\n                    return lfetch(urls, urlStr)\n                } else {\n                    return caches.match(req).then(function (resp) {\n                        return resp || lfetch(urls, urlStr).then(function (res) {\n                            return caches.open(CACHE_NAME).then(function (cache) {\n                                cache.put(req, res.clone());\n                                return res;\n                            });\n                        });\n                    })\n                }\n            }\n        }\n    }\n    return fetch(req)\n}\nconst lfetch = async (urls, url) => {\n    let controller = new AbortController();\n    const PauseProgress = async (res) => {\n        return new Response(await (res).arrayBuffer(), { status: res.status, headers: res.headers });\n    };\n    if (!Promise.any) {\n        Promise.any = function (promises) {\n            return new Promise((resolve, reject) => {\n                promises = Array.isArray(promises) ? promises : []\n                let len = promises.length\n                let errs = []\n                if (len === 0) return reject(new AggregateError('All promises were rejected'))\n                promises.forEach((promise) => {\n                    promise.then(value => {\n                        resolve(value)\n                    }, err => {\n                        len--\n                        errs.push(err)\n                        if (len === 0) {\n                            reject(new AggregateError(errs))\n                        }\n                    })\n                })\n            })\n        }\n    }\n    return Promise.any(urls.map(urls => {\n        return new Promise((resolve, reject) => {\n            fetch(urls, {\n                signal: controller.signal\n            })\n                .then(PauseProgress)\n                .then(res => {\n                    if (res.status == 200) {\n                        controller.abort();\n                        resolve(res)\n                    } else {\n                        reject(res)\n                    }\n                })\n        })\n    }))\n}\n```\n</details>\n</details>\n\n\n\n\n# 全站NPM静态化\n\n> 此法chen独创，是一种比较野路子的手法，但加速效果显著。\n> 通常建议用于Hexo等静态博客，WordPress等需要做好伪静态，并且要配置好动态接口。\n\nhexo作为静态博客有什么好处，那当然是纯静态啦。生成的静态文件随便搬到一个web服务器都能用。\n\n自然就有了接下的骚操作，用npm托管博客，然后在请求的时候用sw劫持并引流到npm镜像，效果就如同本博客所示，加载速度（抛开首屏不谈）接近于闪开。\n\n首先我博客的CI是用GithubAction的，在部署的过程中顺便把html上传到npm是最简单不过的事情，只要在生成代码块后面再加一块：\n\n```yml\n- uses: JS-DevTools/npm-publish@v1\n  with:\n    token: ${{ secrets.NPM }}\n```\n\n配置`NPM`环境变量，之后需要更新的时候叠一个新版本就行。\n\n然后接下来我们就要解决ServiceWorker获取问题。我们先设立一个监听器：\n\n```javascript\nself.addEventListener('fetch', async event => {\n    event.respondWith(handle(event.request))\n});\nconst handle = async(req)=>{\n    const urlStr = req.url\n    const urlObj = new URL(urlStr);\n    const urlPath = urlObj.pathname;\n    const domain = urlObj.hostname;\n    //从这里开始\n}\n```\n\n首先我们要判断一下这个域名是不是博客主域名,不然瞎拦截到其他地方可不好:\n\n```js\nif(domain === \"blog.cyfan.top\"){//这里写你需要拦截的域名\n    //从这里开始处理\n}\n```\n\n我们还要记得给url进行提前处理，剥离出路径，去除参数。在这其中尤其要注意的是默认路由的处理。\n\n通常情况下我们访问一个网址，web服务器会在后面添加`.html`后缀。对于一个默认路径则是`index.html`。\n\n还要注意的是剥离`#`，不然又会获取失败。\n\n定义一个`fullpath`函数，用于预处理和剥离路径：\n\n```js\nconst fullpath = (path) => {\n    path = path.split('?')[0].split('#')[0]\n    if (path.match(/\\/$/)) {\n        path += 'index'\n    }\n    if (!path.match(/\\.[a-zA-Z]+$/)) {\n        path += '.html'\n    }\n    return path\n}\n```\n\n结果类似于：\n\n```\n> fullpath('/')\n'/index.html'\n> fullpath('/p/1')\n'/p/1.html'\n> fullpath('/p/1?q=1234')\n'/p/1.html'\n> fullpath('/p/1.html#QWERT')\n'/p/1.html'\n```\n\n然后再定义一个镜像并发函数，用于生成待获取的网址：\n\n```js\nconst generate_blog_urls = (packagename, blogversion, path) => {\n    const npmmirror = [\n        `https://unpkg.com/${packagename}@${blogversion}/public`,\n        `https://npm.elemecdn.com/${packagename}@${blogversion}/public`,\n        `https://cdn.jsdelivr.net/npm/${packagename}@${blogversion}/public`,\n        `https://npm.sourcegcdn.com/npm/${packagename}@${blogversion}/public`,\n        `https://cdn1.tianli0.top/npm/${packagename}@${blogversion}/public`\n    ]\n    for (var i in npmmirror) {\n        npmmirror[i] += path\n    }\n    return npmmirror\n}\n```\n\n\n接下来我们将其填入主路由中:\n\n```js\nif(domain === \"blog.cyfan.top\"){//这里写你需要拦截的域名\n    return lfetch(generate_blog_urls('chenyfan-blog','1.1.4',fullpath(urlPath)))\n}\n```\n\n然而谨记,npm返回的文件格式通常是text而非html，所以我们还要进一步处理header。处理也简单，连环then下去就行：\n\n```js\nif(domain === \"blog.cyfan.top\"){\n    return lfetch(generate_blog_urls('chenyfan-blog','1.1.4',fullpath(urlPath)))\n    .then(res=>res.arrayBuffer())//arrayBuffer最科学也是最快的返回\n    .then(buffer=>new Response(buffer,{headers:{\"Content-Type\":\"text/html;charset=utf-8\"}}))//重新定义header\n}\n```\n\n那么接下来，除了首屏以外，你的网站相当于托管在全球(包括中国)各个主流cdn服务器中，提速效果无与伦比.如果你将原网站托管在cf，那么你将获得一个打不死，国内加载速度超快(首屏除外)的网站。\n\n## 解放双手 - npm版本自定义更新\n\n有人会问了，我为什么不能直接用latest来获取最新版本，还要手动指定？\n\n简单地说，在生产环境中用@latest指定最新版本是一个很不合理、且非常愚蠢的操作。你永远都不知道对面的缓存什么时候清除，获取到的可能是一年前的版本。\n\n为了节约成本，避免回源，cdn服务商通常会缓存资源，尤其是那些静态资源。以jsd为例，其latest缓存为7天，不过可以手动刷新。unpkg cf边缘2星期，eleme已经将近6个月没更新了。至于那些自建的。你根本搞不懂他什么时候更新，使用latest会导致随机获取到版本，接近无法正常使用。\n\n而指定版本的，cdn通常会永久缓存。毕竟版本定死了东西是不会变的，而请求指定版本的cdn也可以或多或少提升访问速度，因为文件时永久缓存的，HIT的热度比较高。\n\n### sw端\n\n利用npm registry获取最新版本，其官方endpoint如下：\n\n```url\nhttps://registry.npmjs.org/chenyfan-blog/latest\n```\n\n其version字段即最新版本。\n\nnpm registry的镜像也不少，以腾讯/阿里为例：\n\n```url\nhttps://registry.npmmirror.com/chenyfan/latest #阿里，可手动同步\nhttps://mirrors.cloud.tencent.com/npm/chenyfan/latest #腾讯，每日凌晨同步\n```\n\n获取最新版本也不难:\n\n```js\nconst mirror = [\n        `https://registry.npmmirror.com/chenyfan-blog/latest`,\n        `https://registry.npmjs.org/chenyfan-blog/latest`,\n        `https://mirrors.cloud.tencent.com/npm/chenyfan-blog/latest`\n]\nconst get_newest_version = async (mirror) => {\n    return lfetch(mirror, mirror[0])\n        .then(res => res.json())\n        .then(res.version)\n}\n```\n\n在这里还有一个坑点：ServiceWorker的全局变量会在所有页面关闭后销毁。下次启动时会优先响应handle，其定义变量要在handle响应后才会执行。因此，对于最新版本的存储，不能直接定义变量，需要持久化，这里另辟蹊径，采用CacheStorage存储：\n\n\n```js\nself.db = { //全局定义db,只要read和write,看不懂可以略过\n    read: (key, config) => {\n        if (!config) { config = { type: \"text\" } }\n        return new Promise((resolve, reject) => {\n            caches.open(CACHE_NAME).then(cache => {\n                cache.match(new Request(`https://LOCALCACHE/${encodeURIComponent(key)}`)).then(function (res) {\n                    if (!res) resolve(null)\n                    res.text().then(text => resolve(text))\n                }).catch(() => {\n                    resolve(null)\n                })\n            })\n        })\n    },\n    write: (key, value) => {\n        return new Promise((resolve, reject) => {\n            caches.open(CACHE_NAME).then(function (cache) {\n                cache.put(new Request(`https://LOCALCACHE/${encodeURIComponent(key)}`), new Response(value));\n                resolve()\n            }).catch(() => {\n                reject()\n            })\n        })\n    }\n}\n\nconst set_newest_version = async (mirror) => { //改为最新版本写入数据库\n    return lfetch(mirror, mirror[0])\n        .then(res => res.json()) //JSON Parse\n        .then(async res => {\n            await db.write('blog_version', res.version) //写入\n            return;\n        })\n}\n\nsetInterval(async() => {\n    await set_newest_version(mirror) //定时更新,一分钟一次\n}, 60*1000);\n\nsetTimeout(async() => { \n    await set_newest_version(mirror)//打开五秒后更新,避免堵塞\n},5000)\n```\n\n再将上面的生成urls从:\n\n```js\ngenerate_blog_urls('chenyfan-blog','1.1.4',fullpath(urlPath))\n```\n\n改为\n\n```js\n//若第一次没有,则使用初始版本1.1.4,或者你也可以改成latest(不推荐)\ngenerate_blog_urls('chenyfan-blog',await db.read('blog_version') || '1.1.4',fullpath(urlPath))\n```\n\n此后用户加载时，会尽可能的获取最新版本，无需手动更新。\n\n### ci端\n\n有了前端自动更新，我们在上传包的时候还要手动更新`package.json`中的version字段。其实这里也可以直接交给ci处理。\n\n然而需要注意，`npm version patch` 虽然能更新z位数版本，但其更新不会上传到仓库。换句话说，这只能上传一次。因此这个地方我干脆建议用随机数，反正通过api获得的latest都是最新的上传。\n\n案例代码这里不展示，实际上这一步做起来也不难。\n\n\n# 调剂响应\n\n## 缓存 - 互联网上一伟大发明\n\n> 虽然我也不清楚有一小部分人对那么丁点CacheStorage缓存占用那么敏感，但至少，缓存对网站加载速度的提升有极大的帮助。\n\n通常，有大量的资源是访问一个网站重复需要的，对于这些东西，浏览器会自带MemoryCache或DiskCache，但这一类缓存不是持久的，在下一次打开网站的时候缓存不一定生效。而CacheStorage是浏览器自带的缓存桶（Key/Value），这种桶是持久存储，长期有效，而sw是能控制这桶。\n\n而不同的网域资源所应当采取的缓存策略也是不一样的。对于确定版本的静态资源，直接终生缓存；对于有时限的静态资源，应当不缓存或只缓存一小段时间。\n\nCacheStorage不是sw专属的，你可以在前端和sw中同时控制它，这是几分样例代码：\n\n```js\nconst CACHE_NAME = 'cache-v1'; //定义缓存桶名称\ncaches.open(CACHE_NAME).then(async function (cache) {\n    const KEYNAME = new Request('https://example.com/1.xxx') //定义KEY，[Object Request]\n    await cache.put(KEYNAME, new Response('Hello World')); //自定义填入\n    await cache.match(KEYNAME).then(async function (response) {\n        console.log(await response.text()); //匹配并输出\n    })\n    await cache.put(KEYNAME, await fetch('https://example.com/2.xxx').then(res=>res.arrayBuffer())); //使用fetch填入缓存\n    await cache.matchAll().then(function (responses) { //列出所有（也可以根据内容列出指定的项\n        for (let response of responses) {\n            console.log(response.url);\n        }\n    })\n    await cache.delete(KEYNAME) //删除指定项\n});\n```\n\n## SetTimeout - 毫秒级调控响应\n\n对于同一个网页，你需要合理的对他执行决策树，这是目前我的博客[网页]采取的决策树:\n\n![](https://npm.elemecdn.com/chenyfan-os@0.0.0-r18/1.png)\n\njs里有两个对时间控制的古老函数：`SetTimeout`和`SetInterval`.在这里我采用`SetTimeout`,同时并行执行任务.\n\n这里采用代码片段比较容易解释:\n\n```js\nif (请求的网址是博客) {\n    //这里一定要用Promise,这样在之后settimeout就不需要回调,直接Resolve\n    return new Promise(function (resolve, reject) {\n        setTimeout(async () => {\n            if (存在缓存) {\n                setTimeout(() => {\n                    resolve(获取当前页面缓存(请求))\n                }, 200);//200ms表示下面的拉取失败后直接返回缓存,但下面的拉取不会被踢出,更新会在后台执行,会填入缓存,但也不会返回\n                setTimeout(() => {\n                    resolve(\n                        拉取最新版本的网页(请求)\n                            .then(填入缓存并返回内容)//返回缓存\n                    )\n                }, 0);//表示立刻执行,优先级最高\n            } else {\n                setTimeout(() => {\n                    resolve(\n                        拉取最新版本的网页(请求)\n                            .then(填入缓存并返回内容)//返回缓存\n                    )\n                }, 0);//表示立刻执行,优先级最高\n\n                setTimeout(() => {\n                    resolve(返回错误提示())\n                }, 5000)//5000ms后如果没有返回最新内容就直接返回错误提示,如果成功了此次返回是无效的\n            }\n        }, 0)//这里需要一个大settimeout包裹以便于踢出主线程,否则无法并行处理\n\n    })\n}\n```\n\n# 优化首屏\n\n## window.stop - 与死神擦肩而过\n\n事实上，ServiceWorker最显著的缺点是要在第一次加载网页安装后，刷新一次才能激活。即访客第一次访问是不受sw控制的。换句话说，访客首屏不受加速，其加载速度与你的服务器有直接联系 ~~[虽然安装完成后就起飞了,但安装前就是屑]~~。\n\n而本人未成年，浙江的规定又是未成年不得备案，在加上之后备案主题切换异常的麻烦。我的决定是至少高考前都不会备案。那这后果就很直接，我并不能使用国内的cdn节点。再加上我又没这个经济实力用香港CN2或拉iplc专线，对首屏服务器这一块优化其实能做的很少。\n\n更加令人抓狂的是，在首屏加载时，静态资源会被直接获取，并且不缓存，而sw激活后又会强制第二次获取，拉跨速度。\n\n不过我们可以尽可能弱化这一劣势。我们可以用js打断所有的请求，以确保首屏只加载一个html和一个sw.js，其余资源都不会加载，降低首屏加载延迟。\n\n我们尽可能将打断代码提到`<head>` 以确保不被其他资源堵塞，对于hexo来说打开主题的`head.ejs`，在`<head>`标签靠前的位置中加入：\n\n```js\n(async () => {//使用匿名函数确保body已载入\n    /*\n    ChenBlogHelper_Set 存储在LocalStorage中,用于指示sw安装状态\n    0 或不存在 未安装\n    1 已打断\n    2 已安装\n    3 已激活,并且已缓存必要的文件(此处未写出,无需理会)\n    */\n    const $ = document.querySelector.bind(document);//语法糖\n    if ('serviceWorker' in navigator) { //如果支持sw\n        if (Number(window.localStorage.getItem('ChenBlogHelper_Set')) < 1) {\n            window.localStorage.setItem('ChenBlogHelper_Set', 1)\n            window.stop()\n            document.write('Wait')\n        }\n        navigator.serviceWorker.register(`/sw.js?time=${ranN(1, 88888888888888888888)}`)//随机数,强制更新\n            .then(async () => {\n                if (Number(window.localStorage.getItem('ChenBlogHelper_Set')) < 2) {\n                    setTimeout(() => {\n                        window.localStorage.setItem('ChenBlogHelper_Set', 2)\n                        //window.location.search = `?time=${ranN(1, 88888888888888888888)}` //已弃用,在等待500ms安装成功后直接刷新没有问题\n                        window.location.reload()//刷新,以载入sw\n                    }, 500)//安装后等待500ms使其激活\n                }\n            })\n            .catch(err => console.error(`ChenBlogHelperError:${err}`))\n    }\n})()\n```\n\n当然了，这回导致白屏500ms，如果你觉得不好看，也可以和我一样载入一个等待界面，将`document.write()`改为:\n\n```js\ndocument.body.innerHTML = await (await fetch('https://npm.elemecdn.com/chenyfan-blog@1.0.13/public/notice.html')).text()\n```\n\n即可\n\n![](https://npm.elemecdn.com/chenyfan-os@0.0.0-r18/2.png)\n\n\n## 主服务器优化 - 绝望中的最后一根稻草\n\n实际上我一直以为，主服务器的优化在整个网站中是最必要的，也是最不重要的。必要的原因是它关系到最初的加载速度，也是访客中最主要的一环；不重要的是相对于静态资源的记载、页面的渲染和脚本的编译，首屏的加载对整体效果太小了。\n\n尤其是在sw托管后，之后的所有访问，除了sw的更新（以及所有镜像源全炸后），基本与主服务器脱离了关系，正常访问与其没有关系。加速源站实则没有必要。\n\n当然，你说有用吗，那肯定还有点用处，至少首次加载不至于卡人心态。我的要求很简单，能在600ms内完成首次html下载的基本就没问题了。\n最优的无非是香港CN2，不过我们没这个能力。退而求其次，普通的香港服务器我们也能接受。不过依旧是白嫖至上的念头，我才用了Vercel。Vercel也是可以自选节点（主要是亚马逊和谷歌）的，我稍加测试【主要注重可连接性，其次是延迟。丢包和速度作为建站（尤其只有一个10kb的网页）最次】，决定使用一下策略：\n\n```\n电信 104.199.217.228 【台北 谷歌Cloud】 70ms （绕新加坡 但是是质量最好的）\n联通 18.178.194.147 【日本 亚马逊】 45ms （4837和aws在tyo互联）\n移动 18.162.37.140 【香港 谷歌Cloud】 60ms （移动去香港总是最好的选择）\n```\n\n在这里，不推荐其他地区的理由是：\n\n电信：基本上除了台北，去GoogleCloud的都是走日本ntt × ； 亚马逊这一块有大部分绕美，去日本延迟异常的大。\n联通：去香港的绕美了，去日本这一条存在这直接的互联点，负载比较小，延迟也不错。\n移动：没什么好说的，移动互联除了去亚太的都是垃圾。\n\n# 后记\n\n一张思维导图总结全文，你学废了吗？\n\n![](https://npm.elemecdn.com/chenyfan-os@0.0.0-r18/3.png)\n","tags":["ServiceWorker","黑科技"],"categories":["随心扯"]},{"title":"欲善其事，必利其器 - 论如何善用ServiceWorker","url":"/p/c0af86bb.html","content":"\nServiceWorker作为前端革命领袖，毫不夸张地被誉为前端黑科技，此文将阐述如何巧妙的使用它来实现一些看起来匪夷所思的事情。\n\n<!--more-->\n\n---\n\n> **Warning**\n> 此文为最基本的SW使用基础,如果你只是想来白嫖代码的建议退出选择下一篇实操文章.\n\n# 起因 - 巨厦坍塌\n\n2021/12/20日，赶在旧年的末尾，一则`JSdelivrSSL证书错误`缓缓上了v2ex论坛热点。\n\n此前JSD由于各种原因,曾经不正常了一段时间,所以大家并未对此感冒.正当人们以为这只是JSdelivr每年一度的`年经`阵痛,发个issue,过一段时间就好了的时候.官方直接爆出大料:**JSDelivr had lost their ICP license**\n\n由此可见,过去的几年里,当人们发现JSD对个人面向国内加速拥有者无与伦比的效果时,各种滥用方式层出不穷:图床曾一阵流行,国内搜索引擎JSdelivr十有八九都是作为图床的,连PicGo插件都出了Github+JSdelivr图床;猛一点的,直接做视频床,甚至为了突破单文件20M限制开发了一套ts切片m3u8一条龙服务;作妖的,托管了不少突破网络审查的脚本和规则集;寻死的,添加了大量的政治宗教敏感,有些甚至不配称为宗教,直接上来就是骗钱的.\n\njsd并不是没有发布许可条款，但这并不能阻止白嫖大军的进程。在羊毛大军中，只要是你是免费的、公益的，你就要做好被薅爆的结果。但是薅羊毛的前提是羊还活着，倘若羊被薅死了，哪来的羊毛给诸君所薅？\n\n总之，不管怎样，JSDelivr在决定将节点设置为`NearChina`，可以肯定的是，在最近很长一段时间内，我们都无法享受国内外双料同时加速的快感，换句话说，jsd在中国就被永久地打入了冷宫。\n\n视线转向国内，jsd的替代品并不少。早在我写[图床的千层套路](https://blog.cyfan.top/p/eb490c73.html)我就试着假想jsd不可用时，我们该用什么。最终我给出的一份较为完美的答案-npm图床，优点无非就是镜像多速度快，许可条款较为宽松，缺点也很明显，需要安装node，用专门的客户端上传。\n\n那事情就逐渐变得扑朔迷离起来了，我们应当如何选择合理的CDN加速器呢。\n\n这时候，我想起了前端黑科技Serviceworker。是的，这种情况下使用SW最为巧妙不过，它可以在后台自动优选最佳的CDN，甚至可以用黑中黑`Promise.any`打出一套漂亮的并行拳。经过两天的完善，我终于写出了一套具有离线可达、绕备、优选CDN、跟踪统计合一的SW脚本。[此博客使用的SW](/sw.js)\n\n接下来我将从头开始讲述ServiceWorker的妙用。\n\n# Before Start\n\n## What Is The ServiceWorker\n\n网上对于SW的解释比较模糊，在这里，我将其定义为`用户浏览器里的服务器`，功能强大到令人发指。是的，接下来的两张图你应该能显著的看到这一差距：\n\n![没有ServiceWorker中继，平淡无奇](https://npm.elemecdn.com/chenyfan-os@0.0.0-r5/1.jpg)\n\n![ServiceWorker中继，刺激拉满](https://npm.elemecdn.com/chenyfan-os@0.0.0-r5/2.jpg)\n\n在第一张图中，用户和服务器的关系直的就像电线杆，用户想要什么，服务器就还给他什么。\n\n第二张图中，用户在被ServiceWorker控制的页面中，无论向哪个服务器发起请求，其过程都会被SW捕获，SW可以仿佛不存在一般单纯地请求服务器，返回原本应该返回的内容【透明代理】；也可以对当前服务器返回的内容进行随意的捏造、修改【请求修改结果】；甚至可以将请求指向完全另一台服务器，返回不是此服务器应该返回的内容【移花接木】；当然，SW也可以直接返回已经存储在本地的文件，甚至离线的时候也能返回【离线访问可达性】。\n\n由于SW对于用户页面的操纵实在过于强大，因此，它被设计成`不可跨域请求`、`SW脚本必须在同一域名下`、`必须在HTTPS条件下运行`、`不可操纵DOM和BOM`，同样的，为了避免阻塞和延迟，SW也被特意设计成`完全异步的`。这些点将会在后面一一讲述。\n\n> 当然，开发者至上，为了方便本地调试，本机地址`localhost`和`127.0.0.1`被浏览器所信任，允许以`非HTTPS`方式运行serviceworker。\n\n## What Relationship Between ServiceWorker and PWA\n\n很多人看到sw，第一反应是PWA，即渐进式Web应用。实际上，SW确实是PWA的核心与灵魂，但SW在PWA中起的主要作用是缓存文件，提供给离线访问。并没有完整地发挥出SW的巧妙用法。\n\nSW可以完全脱离PWA存在，当然，PWA可离不开SW ：）\n\n## And WorkBox ?\n\nWorkBox是谷歌开发的一款基于SW的缓存控制器，其主要目的是方便维护PWA。核心依旧是SW，但还是没有SW原本的自定义程度高（\n\n## Why Not WorkBox ?\n\n首先，博客呢，是没有必要用PWA，有SW做中间件足矣。同时，WorkBox只能简单的缓存数据，并不能做到拦截篡改请求的功能，尤其不能精准把握每一个资源的缓存情况，自定义程度并不高。\n\n~~自己编写SW，格局就打开了~~\n\n# Start From Zero\n\n## 安装 / Install\n\n首先，SW的本质是JS脚本，要安装它必须要经过一个html。毕竟，只有拿到了html，JS才能运行于DOM上下文。\n\n剥离层层加成，安装的代码只有一行\n\n```JavaScript\nnavigator.serviceWorker.register('/sw.js')\n```\n\n其中，`/sw.js`即为ServiceWorker脚本所在，由于安全性，你不能加载跨域的SW。\n\n例如，当前网页为`https://blog.cyfan.top`，以下加载位置是允许的\n\n```url\n/sw.js\nhttps://blog.cyfan.top/sw.js\n```\n\n以下加载是不允许的:\n\n```url\nhttp://blog.cyfan.top/sw.js#非HTTPS\nhttps://cyfan.top/sw.js#非同一域名，视为跨域\nhttps://119.91.80.151:59996/sw.js#虽然为同一文件,但非同一域名，视为跨域\n./sw.js#容易造成SW脚本获取路径不一致\n```\n\n在加载前，我们最好判断一下dom是否加载完了，不然安装sw可能会卡dom\n\n加载完成后，register函数将返回一个`Promise`，由于前端大多不适用于`异步`，我们通常以`同步`的方式`.then()`和`.catch()`来获取是否加载成功。\n\n为了方便判断脚本是否能够加载，我们还要判断navigator里有无sw这一属性`'serviceWorker' in navigator`。\n\n由于SW安装后，页面需要刷新后才能交给SW所宰割，同时为了避免浏览器缓存的影响，我通常采用修改`search`的方式强刷新，而不是通过`reload`函数。同样的，为了避免刚安装完就刷新的尴尬感，建议用`setTimeout`延迟一秒刷新。\n\n简易的完整安装代码如下:\n\n```html\n<script>\nwindow.addEventListener('load', async () => {\n    navigator.serviceWorker.register(`/sw.js?time=${new Date().getTime()}`)\n        .then(async reg => {\n            //安装成功，建议此处强刷新以立刻执行SW\n            if (window.localStorage.getItem('install') != 'true') {\n                window.localStorage.setItem('install', 'true');\n                setTimeout(() => {\n                    window.location.search = `?time=${new Date().getTime()}`\n                }, 1000)\n            }\n        }).catch(err => {\n            //安装失败，错误信息会由err传参\n        })\n});\n</script>\n```\n\n一刷新，世界就变成了ServiceWorker的瓮中之鳖，接下来，该是SW脚本正式登场的时候了。\n\n## SW安装初始化 / Installations\n\n首先，先尴尬的开一个空缓存列表：\n\n```js\nconst CACHE_NAME = 'ICDNCache';//可以为Cache版本号，但这样可能会导致缓存冗余累积\nlet cachelist = [];\n```\n\n`cachelist`里面填写的是预缓存网址，例如在离线时返回的错误页面。此处不宜添加过多网址，此处点名@一下Akilar。\n\n此处我建议只缓存离线页面展示的内容:\n\n```js\nlet cachelist = [\n    '/offline.html',\n    'https://npm.elemecdn.com/chenyfan-os@0.0.0-r6'\n];\n```\n\n同时监听sw安装时开启此缓存空间：\n\n```js\nself.addEventListener('install', async function (installEvent) {\n    self.skipWaiting();\n    installEvent.waitUntil(\n        caches.open(CACHE_NAME)\n            .then(function (cache) {\n                console.log('Opened cache');\n                return cache.addAll(cachelist);\n            })\n    );\n});\n```\n\n由于SW完全没有办法访问DOM，因此对于全局变量，不应当用`window`，而是`self`指代自己。\n\n`addEventListener`这一监听器将监听`install`,也就是这一段代码只会在脚本首次安装和更新时运行.\n\n`skipWaiting`的作用是促进新版本sw跳过waiting这一阶段，直接active。\n\n> 关于SW的状态（waiting，installing，activing）将在文后详细解释。\n\n`installEvent.waitUntil`的作用是直接结束安装过程的等待，待会在后台完成开启缓存空间这一操作。\n\n\n`cache.addAll`将会直接获取`cachelist`里面所有的网址并直接缓存到CacheStorage。如果此处网址过多，将在页面加载时疯狂请求所有的url~~(例如1k个)~~\n\n现在，SW初始化已经完成了。接下来，我将讲述SW如何捕获页面的请求。\n\n## 捕获请求 / Fetch Event\n\n### 添加监听器 / AddEventListener\n\n```js\nself.addEventListener('fetch', async event => {\n    event.respondWith(handle(event.request))\n});\n\nconst handle = async(req)=>{\n    //do something\n}\n```\n\n第一行很简单，绑定一个监听器，监听`fetch`事件，即网页向服务器获取请求，也就是相当于前端的`XMLHTTPRequest`\n\n`event.respondWith`即设定返回内容，交给`handle`主函数处理，传参`event.request`。这是一个`Request`对象，里面包含了请求的详细信息。\n\n接下来，我们开始实战吧。\n\n> 以下所有内容均针对handle修改\n\n### 透明代理 / Transparent Proxy\n\n顾名思义，此实战脚本的作用是SW代理目前的所有流量但不进行修改，仿佛SW不存在一般。\n\n```js\nconst handle = async(req)=>{\n    return fetch(req)\n}\n```\n\n`fetch`这个函数相当于前端的`ajax`或者`XMLHTTPRequest`，作用是发起一个请求，获得一个返回值。由于sw不可访问`window`，在sw中是无法使用`ajax`或`XMLHTTPRequest`。同时，`fetch`是一个异步函数，直接调用它会返回一个`Promise`。\n\n`fetch`只能传递`Requset`对象,而`Requset`对象有两个参数`(url,[option])`,第一个参数是网址,第二个参数为`Request`的内容,例如`body`或`header`。\n\n此脚本适用于卸载`ServiceWorker`的替换脚本。因为sw在无法拉取新版本时不会主动卸载，依旧保持运行，填入一个透明代理sw即可。\n\n由于SW冷启动【即页面关闭后SW】处于暂停状态是从硬盘读取的，这会导致第一次请求有少许性能延迟[~10ms]。\n\n### 篡改请求 / Edit Requset\n\n对于一张图片，有时候服务端会变态到让你必须用`POST`协议才能获得，此时用SW篡改最为方便。\n\n```js\nconst handle = async (req) => {\n    if ((req.url.split('/'))[2].match('xxx.com')) {\n        //xxx.com为图片所在域名\n        return fetch(req.url, {\n            method: \"POST\"\n        })\n    }\n    return fetch(req)\n}\n```\n\n> 注意，在ServiceWorker里面，header头是不能修改refferer和origin的，因此此方法无法绕开新浪图床反盗链\n\n### 篡改响应 / Edit Response\n\n这个例子会检测返回内容，若为html，将把所有的\"TEST\"都替换成\"SHIT\"\n\n```js\nconst handle = async (req) => {\n    const res = await fetch(req)\n    const resp = res.clone()\n    if (!!resp.headers.get('content-type')) {\n        if (resp.headers.get('content-type').includes('text/html')) {\n            return new Response((await resp.text()).replace(/TEST/g, 'SHIT'), {\n                headers: resp.headers,\n                status: resp.status\n            })\n        }\n    }\n    return resp\n}\n```\n\n`const resp = res.clone()`由于`Response`的`body`一旦被读取，这个`body`就会被锁死，再也无法读取。`clone()`能够创造出响应的副本用于处理。\n\n`resp.headers.get('content-type')`通过读取响应的头，判断是否包含`text/html`，如果是，将响应以`text()`异步流的方式读取，然后正则替换掉响应内容，并还原头和响应Code。\n\n返回的内容必须是`Response`对象，所以`new Response`构建一个新对象，并直接返回。不匹配html头将直接原封不动地透明代理。\n\n### 移花接木 / Graft Request To Another Server\n\n`unpkg.zhimg.com`是`unpkg.com`的镜像网站。此脚本将会把所有的`unpkg.com`流量直接拦截到`unpkg.zhimg.com`，用于中国大陆内CDN加速。\n\n由于npm镜像固定为GET请求方式并且没有其他鉴权需求，所以我们没有必要还原`Request`其他数据。\n\n```js\nconst handle = async (req) => {\n    const domain = req.url.split('/')[2];\n    if (domain.match(\"unpkg.com\")) {\n        return fetch(req.url.replace(\"https://unpkg.com\", \"https://zhimg.unpkg.com\"));\n    }\n    else {\n        return fetch(req)\n    }\n}\n```\n\n`domain.match`捕获请求中是否有待替换域名，检查出来后直接`replace`掉域名，如果没有匹配到，直接透明代理走掉。\n\n\n\n\n### 并行请求 / Request Parallelly\n\nSW中又一大黑科技隆重登场=>`Promise.any`，这个函数拥有另外两个衍生兄弟`Promise.all`&`Promise.race`。下面我将简单介绍这三种方式\n\n#### Promose.all\n\n当列表中所有的`Promise`都`resolve`[即成功]后，这个函数才会返回`resolve`，只要有一个返回`reject`，整个函数都会`reject`。\n\n```js\nPromise.all([\n    fetch('https://unpkg.com/jquery'),\n    fetch('https://cdn.jsdelivr.net/npm/jquery'),\n    fetch('https://unpkg.zhimg.com/jquery')\n])\n```\n\n这个函数将会请求三个网址，当每一个网址都链接联通后，整个函数将会返回一个列表：\n\n```js\n[Response1,Response2,Response3]\n```\n\n当任何一个`fetch`失败[即`reject`]后，整个`Promise.all`函数都会直接`reject`并报错。\n\n此函数可以检测网络连通性，由于采取并行处理，相比以前的循环效率要高不少。\n\n这是一段检测国内国外网络连通性的测试。\n\n没有采用`Promise.all`的代码和效果：\n\n```js\nconst test = async () => {\n    const url = [\n        \n        \"https://cdn.jsdelivr.net/npm/jquery@3.6.0/package.json\",\n        \"https://unpkg.com/jquery@3.6.0/package.json\",\n        \"https://unpkg.zhimg.com/jquery@3.6.0/package.json\"\n    ]\n    flag = true\n    for (var i in url) {\n        try {\n            const res = await fetch(url[i])\n            if (res.status !== 200) {\n                flag = false\n            }\n        }catch(n){\n            return false\n        }\n    }\n    return flag\n}\n```\n\n![](https://npm.elemecdn.com/chenyfan-os@0.0.0-r7/1.png)\n\n采用循环，`await`会堵塞循环，直到这次请求完成后才能执行下一个。如果有任何一个url长时间无法联通，将会导致极长的检测时间浪费。\n\n\n```js\n\nconst test = () => {\n    const url = [\n        \"https://cdn.jsdelivr.net/npm/jquery@3.6.0/package.json\",\n        \"https://unpkg.com/jquery@3.6.0/package.json\",\n        \"https://unpkg.zhimg.com/jquery@3.6.0/package.json\"\n    ]\n    return Promise.all(url.map(url => {\n        return new Promise((resolve, reject) => {\n            fetch(url)\n                .then(res => {\n                    if (res.status == 200) {\n                        resolve(true)\n                    } else {\n\n                        reject(false)\n                    }\n                })\n                .catch(err => {\n                    reject(false)\n                })\n        })\n\n    }\n    )).then(res => {\n        return true\n    }).catch(err => {\n        return false\n    })\n}\n```\n![](https://npm.elemecdn.com/chenyfan-os@0.0.0-r7/2.png)\n\n`Promise.all`几乎在一瞬间请求所有的url，其请求时并行，每一个请求并不会堵塞其他请求，函数总耗时为最长请求耗时。\n\n#### Promise.race\n\n此函数也是并行执行，不过与all不同的是，只要有任何一个函数完成，就立刻返回，无论其是否`reject`或者`resolve`。\n\n这个函数比较适合用于同时请求一些不关心结果，只要访问达到了即可，例如统计、签到等应用场景。\n\n#### Promise.any\n\n这个函数非常的有用，其作用和`race`接近，不过与之不同的是，`any`会同时检测结果是否`resolve`。其并行处理后，只要有任何一个返回正确，就直接返回哪个最快的请求结果，返回错误的直接忽视，除非所有的请求都失败了，才会返回`reject`\n\n这是一段同时请求`jquery`的`package.json`代码，它将从四个镜像同时请求：\n\n```js\nconst get_json = () => {\n    return new Promise((resolve, reject) => {\n        const urllist = [\n            \"https://cdn.jsdelivr.net/npm/jquery@3.6.0/package.json\",\n            \"https://unpkg.com/jquery@3.6.0/package.json\",\n            \"https://unpkg.zhimg.com/jquery@3.6.0/package.json\",\n            \"https://npm.elemecdn.com/jquery@3.6.0/package.json\"\n        ]\n        Promise.any(urllist.map(url => {\n            fetch(url)\n                .then(res => {\n                    if (res.status == 200) {\n                        resolve(res)\n                    } else {\n                        reject()\n                    }\n                }).catch(err => {\n                    reject()\n                })\n        }))\n    })\n}\n\nconsole.log(await(await get_json()).text())\n```\n\n![](https://npm.elemecdn.com/chenyfan-os@0.0.0-r7/3.png)\n\n函数将会在`21ms`上下返回json中的数据。\n\n此函数的好处在于可以在用户客户端判断哪一个镜像发挥速度最快，并保证用户每一次获取都能达到最大速度。同时，任何一个镜像站崩溃了都不会造成太大的影响，脚本将自动从其他源拉取信息。\n\n除非所有源都炸了，否则此请求不会失败。\n\n但是，我们会额外地发现，当知乎镜像返回最新版本后，其余的请求依旧在继续，只是没有被利用到而已。\n\n这会堵塞浏览器并发线程数，并且会造成额外的流量浪费。所以我们应该在其中任何一个请求完成后就打断其余请求。\n\n`fetch`有一个`abort`对象，只要刚开始`new AbortController()`指定控制器，在`init`的里面指定控制器的`signal`即可将其标记为待打断函数，最后`controller.abort()`即可打断。\n\n那么，很多同学就会开始这么写了:\n\n```js\nconst get_json = () => {\n    return new Promise((resolve, reject) => {\n        const controller = new AbortController();\n        const urllist = [\n            \"https://cdn.jsdelivr.net/npm/jquery@3.6.0/package.json\",\n            \"https://unpkg.com/jquery@3.6.0/package.json\",\n            \"https://unpkg.zhimg.com/jquery@3.6.0/package.json\",\n            \"https://npm.elemecdn.com/jquery@3.6.0/package.json\"\n        ]\n        Promise.any(urllist.map(url => {\n            fetch(url,{\n                signal: controller.signal\n            })\n                .then(res => {\n                    if (res.status == 200) {\n                        controller.abort();\n                        resolve(res)\n                    } else {\n                        reject()\n                    }\n                }).catch(err => {\n                    reject()\n                })\n        }))\n    })\n}\n\nconsole.log(await(await get_json()).text())\n```\n\n但很快，你就会发现它报错了：`Uncaught DOMException: The user aborted a request.`，并且没有任何数据输出。\n\n让我们看一下Network选项卡：\n\n![](https://npm.elemecdn.com/chenyfan-os@0.0.0-r7/4.png)\n\n\n其中，知乎返回的最快，但他并没有完整的返回文件[源文件1.8KB，但他只返回了1.4KB]。这也直接导致了整个函数的`fail`。\n\n原因出在`fetch`上，这个函数在获得响应之后就立刻`resolve`了`Response`，但这个时候`body`并没有下载完成，即`fetch`的返回基于状态的而非基于响应内容，当其中`fetch`已经拿到了完整的状态代码，它就立刻把`Response`丢给了下一个管道函数，而此时`status`正确，`abort`打断了包括这一个`fetch`的所有请求，`fetch`就直接工作不正常。\n \n我个人采取的方式是读取`arrayBuffer`，阻塞`fetch`函数直到把整个文件下载下来。函数名为`PauseProgress`\n\n```js\nconst get_json = () => {\n    return new Promise((resolve, reject) => {\n        const controller = new AbortController();\n        const PauseProgress = async (res) => {\n            return new Response(await (res).arrayBuffer(), { status: res.status, headers: res.headers });\n        };\n        const urllist = [\n            \"https://cdn.jsdelivr.net/npm/jquery@3.6.0/package.json\",\n            \"https://unpkg.com/jquery@3.6.0/package.json\",\n            \"https://unpkg.zhimg.com/jquery@3.6.0/package.json\",\n            \"https://npm.elemecdn.com/jquery@3.6.0/package.json\"\n        ]\n        Promise.any(urllist.map(url => {\n            fetch(url, {\n                signal: controller.signal\n            })\n                .then(PauseProgress)\n                .then(res => {\n                    if (res.status == 200) {\n                        controller.abort();\n                        resolve(res)\n                    } else {\n                        reject()\n                    }\n                }).catch(err => {\n                    reject()\n                })\n        }))\n    })\n}\n\nconsole.log(await(await get_json()).text())\n```\n\n![](https://npm.elemecdn.com/chenyfan-os@0.0.0-r7/5.png)\n\n在这其中通过`arrayBuffer()`方法异步读取`res`的`body`，将其读取为二进制文件，并新建一个新的`Response`，还原状态和头，然后丢给管道函数同步处理。\n\n在这里，我们就实现了暴力并发，以流量换速度的方式。同时也获得了一个高可用的SW负载均衡器。\n\n这一段函数可以这样写在SW中：\n\n\n```js\n//...\nconst lfetch = (urllist) => {\n    return new Promise((resolve, reject) => {\n        const controller = new AbortController();\n        const PauseProgress = async (res) => {\n            return new Response(await (res).arrayBuffer(), { status: res.status, headers: res.headers });\n        };\n        Promise.any(urllist.map(url => {\n            fetch(url, {\n                signal: controller.signal\n            })\n                .then(PauseProgress)\n                .then(res => {\n                    if (res.status == 200) {\n                        controller.abort();\n                        resolve(res)\n                    } else {\n                        reject()\n                    }\n                }).catch(err => {\n                    reject()\n                })\n        }))\n    })\n}\nconst handle = async (req) => {\n    const npm_mirror = [\n        'https://cdn.jsdelivr.net/npm/',\n        'https://unpkg.com/',\n        'https://npm.elemecdn.com/',\n        'https://unpkg.zhimg.com/'\n    ]\n    for (var k in npm_mirror) {\n        if (req.url.match(npm_mirror[k]) && req.url.replace('https://', '').split('/')[0] == npm_mirror[k].replace('https://', '').split('/')[0]) {\n            return lfetch((() => {\n                let l = []\n                for (let i = 0; i < npm_mirror.length; i++) {\n                    l.push(npm_mirror[i] + req.url.split('/')[3])\n                }\n                return l\n            })())\n        }\n    }\n    return fetch(req)\n}\n```\n\n另外,`Promise.any`,兼容性比较差:\n\n![](https://npm.elemecdn.com/chenyfan-os@0.0.0-r9/1.png)\n\n因此,我的解决办法是判断浏览器如果不支持,就提前polyfill一下:\n\n```js\nif (!Promise.any) {\n        Promise.any = function (promises) {\n            return new Promise((resolve, reject) => {\n                promises = Array.isArray(promises) ? promises : []\n                let len = promises.length\n                let errs = []\n                if (len === 0) return reject(new AggregateError('All promises were rejected'))\n                promises.forEach((promise) => {\n                    promise.then(value => {\n                        resolve(value)\n                    }, err => {\n                        len--\n                        errs.push(err)\n                        if (len === 0) {\n                            reject(new AggregateError(errs))\n                        }\n                    })\n                })\n            })\n        }\n    }\n```\n\n## 缓存控制 / Cache\n\n\n### 持久化缓存 / Cache Persistently\n\n对于来自CDN的流量，大部分是持久不变的，因此，如果我们将文件获得后直接填入缓存，之后访问也直接从本地缓存中读取，那将大大提升访问速度。\n\n```js\nconst handle = async (req) => {\n    const cache_url_list = [\n        /(http:\\/\\/|https:\\/\\/)cdn\\.jsdelivr\\.net/g,\n        /(http:\\/\\/|https:\\/\\/)cdn\\.bootcss\\.com/g,\n        /(http:\\/\\/|https:\\/\\/)zhimg\\.unpkg\\.com/g,\n        /(http:\\/\\/|https:\\/\\/)unpkg\\.com/g\n    ]\n    for (var i in cache_url_list) {\n        if (req.url.match(cache_url_list[i])) {\n            return caches.match(req).then(function (resp) {\n                return resp || fetch(req).then(function (res) {\n                    return caches.open(CACHE_NAME).then(function (cache) {\n                        cache.put(req, res.clone());\n                        return res;\n                    });\n                });\n            })\n        }\n    }\n    return fetch(req)\n}\n```\n\n`cache_url_list`列出所有待匹配的域名(包括http/https头是为了避免误杀其他url)，然后`for`开始遍历待列表，如果url中匹配到了，开始执行返回缓存操作。\n\ncache是一个近似于Key/Value(键名/键值)，只要有对应的`Request`(`KEY`)，就能匹配到响应的`Response`(`VALUE`)。\n\n`caches.match(req)`将会试图在CacheStorage中匹配请求的url获取值，然后丢给管道同步函数`then`，传参`resp`为Cache匹配到的值。\n\n此时管道内将尝试返回resp，如果resp为`null`或`undefined`[即获取不到对应的缓存]，将执行fetch操作，fetch成功后将`open`打开CacheStorage，并`put`放入缓存。此时如果`fetch`失败将直接报错，不写入缓存。\n\n在下一次获取同一个URL的时候，缓存匹配到的将不再是空白值，此时`fetch`不执行，直接返回缓存，大大提升了速度。\n\n由于npm的cdn对于latest缓存并不是持久有效的，所以我们最好还是判断一下url版本中是否以@latest为结尾。\n\n```js\nconst is_latest = (url) => {\n    return url.replace('https://', '').split('/')[1].split('@')[1] === 'latest'\n}\n//...\nfor (var i in cache_url_list) {\n    if (is_latest(req.url)) { return fetch(req) }\n    if (req.url.match(cache_url_list[i])) {\n        return caches.match(req).then(function (resp) {\n            //...\n        })\n    }\n}\n```\n\n\n### 离线化缓存 / Cache For Offline\n\n对于博客来说，并不是所有内容都是一成不变的。传统PWA采用SW更新同时刷新缓存，这样不够灵活，同时刷新缓存的版本号管理也存在着很大的漏洞，长时间访问极易造成庞大的缓存冗余。因此，对于博客的缓存，我们要保证用户每次获取都是最新的版本，但也要保证用户在离线时能看到最后一个版本的内容。\n\n因此，针对博客来说，策略应该是先获取最新内容，然后更新本地缓存，最后返回最新内容；离线的时候，尝试访问最新内容会回退到缓存，如果缓存也没有，就回退到错误页面。\n\n即：\n\n```\nOnline:\n发起Request => 发起fetch => 更新Cache => 返回Response\nOffline:\n发起Request => 获取Cache => 返回Response\n```\n\n\n```js\nconst handle = async (req) => {\n    return fetch(req.url).then(function (res) {\n        if (!res) { throw 'error' } //1\n        return caches.open(CACHE_NAME).then(function (cache) {\n            cache.delete(req);\n            cache.put(req, res.clone());\n            return res;\n        });\n    }).catch(function (err) {\n        return caches.match(req).then(function (resp) {\n            return resp || caches.match(new Request('/offline.html')) //2\n        })\n    })\n}\n```\n\n`if (!res) { throw 'error' }` 如果没有返回值，直接抛出错误，会被下面的Catch捕获，返回缓存或错误页面\n\n`return resp || caches.match(new Request('/offline.html'))` 返回缓存获得的内容。如果没有，就返回从缓存中拿到的错误网页。此处offline.html应该在最开始的时候就缓存好\n\n## 持久化存储 / Storage Persistently\n\n由于sw中无`window`，我们不能使用`localStorage`和`sessionStorage`。SW脚本会在所有页面都关闭或重载的时候丢失原先的数据。因此，如果想要使用持久化存储，我们只能使用`CacheAPI`和`IndexdDB`。\n\n### IndexdDB\n\n这货结构表类型类似于`SQL`，能够存储JSON对象和数据内容，但版本更新及其操作非常麻烦，因此本文不对此做过多解释。\n\n### CacheAPI\n\n这东西原本是用来缓存响应，但其本身的特性我们可以将其改造成一个简易的Key/Value数据表，可以存储文本/二进制，可扩展性远远比IndexdDB要好。\n\n```js\nself.CACHE_NAME = 'SWHelperCache';\nself.db = {\n    read: (key) => {\n        return new Promise((resolve, reject) => {\n            caches.match(new Request(`https://LOCALCACHE/${encodeURIComponent(key)}`)).then(function (res) {\n                res.text().then(text => resolve(text))\n            }).catch(() => {\n                resolve(null)\n            })\n        })\n    },\n    read_arrayBuffer: (key) => {\n        return new Promise((resolve, reject) => {\n            caches.match(new Request(`https://LOCALCACHE/${encodeURIComponent(key)}`)).then(function (res) {\n                res.arrayBuffer().then(aB => resolve(aB))\n            }).catch(() => {\n                resolve(null)\n            })\n        })\n    },\n    write: (key, value) => {\n        return new Promise((resolve, reject) => {\n            caches.open(CACHE_NAME).then(function (cache) {\n                cache.put(new Request(`https://LOCALCACHE/${encodeURIComponent(key)}`), new Response(value));\n                resolve()\n            }).catch(() => {\n                reject()\n            })\n        })\n    }\n}\n```\n\n使用操作：\n\n写入key，value:\n\n```js\nawait db.wtite(key,value)\n```\n\n以文本方式读取key：\n\n```js\nawait db.read(key)\n```\n\n以二进制方式读取key：\n\n```js\nawait db.read_arrayBuffer(key)\n```\n\n其余的blob读取、delete操作此处不过多阐述。\n\n\n## 页面与SW通信 / Build Communication with Page and ServiceWorker\n\n### 单向连接 / Unidirectional Connect\n\n### Clients To SW\n\n浏览器 => SW\n\nServiceWorker中有一个非常简单的API`postMessage`,全路径为`navigator.serviceWorker.controller.postMessage`.\n\n因此,如果你只是作为页面单方面传递给SW,此api是个不错的选择.\n\n前端写法\n\n```js\nconst data = 123\nnavigator.serviceWorker.controller.postMessage(data)\n//发送123\n```\n\nSW接收\n\n```js\nself.addEventListener('message', (event) => {\n  console.log(event.data)\n  //输出123\n});\n```\n\n此方法可用于单方面向SW提交数据,但无需返回值.比如提示SW可以SkipWaiting,或者提交前端统计数据等等.\n\n\n#### SW To Clients\n\n首先,Clients必须要从SW中的一个event事件中获取,比如`fetch`.无法从`message`事件中获取client.\n\n```js\naddEventListener('fetch', event => {\n    event.waitUntil(async function () {\n        if (!event.clientId) return;\n        const client = await clients.get(event.clientId);\n        if (!client) return;\n        const data = 123;\n        client.postMessage(data);\n    }());\n});\n```\n\n### 双向通讯 / Connect Each\n\n浏览器 <=> SW\n\n我们拥有两种方式双向通讯:\n\n1. [Broadcast Channel API](https://developer.mozilla.org/en-US/docs/Web/API/Broadcast_Channel_API) 多对多,广播形式.\n2. [Message Channel](https://developer.mozilla.org/en-US/docs/Web/API/MessageChannel) 一对一\n\n\n\n#### MessageChannel\n\n顾名思义，MessageChannel API 设置了一个可以发送消息的通道。\n\n该实现可以归结为3个步骤。\n\n1.在两侧设置事件侦听器以接收`message` 事件\n2.通过发送`port`并将其存储在SW中，建立与SW的连接。\n3.使用存储的`port`回复客户端\n\n前端写法\n\n```js\nconst messageChannel = new MessageChannel();\nnavigator.serviceWorker.controller.postMessage({\n  type: 'INIT',//发送init信息,表示以port2为接收端[即SW的发送端]\n}, [messageChannel.port2]);\nmessageChannel.port1.onmessage = (event) => {\n  //监听port1\n  navigator.serviceWorker.controller.postMessage({\n    type: 'PING'//发送PING\n  });\n};\n```\n\n\nSW端写法\n\n```js\nself.addEventListener(\"message\", event => {\n    const data = event.data;\n    if (!!data) {\n        switch (data.type) {\n            case 'INIT':\n                self.ClientPort = event.ports[0];\n            default:\n                self.ClientPort.postMessage({\n                    type: 'DATA',\n                    data: 'pong'\n                });\n        }\n    }\n})\n```\n\n然后查看控制台,你就会看到里面一直在乒乒乓乓,说明成功了.\n\n我们简单的改写一下,变成异步形式传输数据:\n\n```js\nconst mCh = {\n        init: () => {\n            window.messageChannel = new MessageChannel();\n            navigator.serviceWorker.controller.postMessage({\n                type: 'INIT',\n            }, [messageChannel.port2]);\n        },\n        send: (data) => {\n\n            return new Promise((resolve, reject) => {\n                const uuid = (() => {\n                    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function (c) {\n                        var r = Math.random() * 16 | 0, v = c == 'x' ? r : (r & 0x3 | 0x8);\n                        return v.toString(16);\n                    });\n                })()\n                navigator.serviceWorker.controller.postMessage({\n                    type: 'DATA',\n                    data: data,\n                    id: uuid\n                });\n                setTimeout(() => {\n                    reject({\n                        message: 'timeout',\n                        ok: false\n                    })\n                }, 2000);\n                messageChannel.port1.onmessage = (event) => {\n                    if (event.data.id === uuid) {\n                        resolve({\n                            message: event.data.data,\n                            ok: true\n                        })\n                    };\n                }\n            })\n        }\n    }\n```\n\n由于MessageChannel特性,一个port只要不是连续传输数据就会被断开.所以每次传输时我们要先初始化,后发送数据.\n\n由于传输时无状态的,我们将每一个包都打上特定的uuid,返回包里也写上对应的uuid即可判断那个包是哪个对应的返回值.\n\nSW端也要做一点点相应的改动\n\n```js\nself.ClientPort.postMessage({\n//...\nid: data.id\n});\n```\n\n这样,一个兼容性较好的SW双向传输就解决了.\n\n#### Broadcast Channel \n\n> 请注意,BroadCast虽然写法建议,但是对浏览器兼容性要求非常高[Chrome 54,IOS Safari全线不支持].用此api请三思.\n\n> 另外,由于是广播形式,一个页面如果有多个SW,他们会同时收到消息.\n\n前端\n\n```js\nconst broadcast = new BroadcastChannel('Channel Name');\nconst send_ping = () => {\n    broadcast.postMessage({\n        type: 'PING'\n    });\n}\nbroadcast.onmessage = (event) => {\n    console.log('PONG')\n    setTimeout(() => {\n        send_ping()\n    }, 500);\n};\nsend_ping()\n```\n\nSW端\n\n```js\nconst broadcast = new BroadcastChannel('Channel Name');\nbroadcast.onmessage = (event) => {\n    broadcast.postMessage({ type: \"PONG\" })\n};\n```\n\n只要ChannelName对应,即可在里面顺利传输消息.\n\n\n## 细节与注意 / Something Small But Need to Be Mentioned\n\n### 无法修改的 Header\n\n由于ServiceWorker本质上仍然属于浏览器,因此,你无法控制例如header中的`Host`\\\\`Refferer`\\\\`Access-Control-Allow-Origin`用于绕过防盗链\\CORS\\指定host选择ip\n\n\n### 难以卸载的 SW\n\nSW一大特性,一旦被安装,就不能通过传统方式卸载掉.\n\n如果你直接删除`sw.js`文件并删除安装代码,那么,新用户是不会被安装的,但是原先已经安装过的用户sw会继续劫持这他们的网页,导致老用户网页不更新或者出现异常.\n\n正确的删除方法是将安装代码改成卸载代码:\n\n```\nnavigator.serviceWorker.getRegistrations().then(function(registrations) {\n for(let registration of registrations) {\n  registration.unregister()\n} })\n```\n\n并将sw内容改成透明代理,方便没有卸载的用户正常使用.\n\n\n### 堵塞整个浏览器的代码\n\n由于SW运行在DOM上下文,如果在sw中执行一些消耗资源的代码会直接耗尽浏览器资源,与dom不同的是,dom耗资源代码只会堵塞一个线程,另一个线程依旧可以正常工作,而sw一旦堵塞会将整个浏览器堵死.因此sw固然可以更快的计算,但万不可将一些极易死机的代码交给sw处理.\n\n\n\n\n# End\n\n这篇文章结尾的很仓促,毕竟已经快拖了一个月了,也有很多东西没有讲清楚,未来可能会小修小改.\n\n篇幅所限,一些sw其他功能并没有详细讲述,比如后台更新或者推送通知.这些功能在实际开发中并不是特别有用,或者在国内大环境下并不适合.可能这些功能会在下一篇文章,sw的实操中讲述.\n\n停下笔的时候,hexo统计这篇文章已经将近1万字,阅读时间近100分钟.不过我认为这值得,毕竟sw就是这么一个凭借着奇思妙想就能绽放出Spark的事物.唯有独特的创造力才能激发无限可能.\n\n当然,这篇文章讲述的都是些非常基础的东西,那在下一篇文章,我会贴出一个个demo,希望你们能对这些充满着智慧的样例激发你们的灵感.\n\n另外,在祝贺你们,虎年大吉,新年快乐!","tags":["ServiceWorker","黑科技","JSdelivr"],"categories":["随心扯"]},{"title":"为什么是APP而不是网页","url":"/p/c0af86a9.html","content":"\n一个简单的功能，完全可以在浏览器内实现，凭什么国内某些软件这么希望你去下载，去使用他们的app？\n\n<!--more-->\n\n---\n\n就在不久前，我是真的体会到了什么叫流氓厂商。点名批评一下百度，我苹果手机Safari随便在百度上搜索点什么，还没把营销号、广告和垃圾信息从眼中剔除，突然间，AppStore界面平移到我眼前，一个叫`百度`的软件可怜巴巴的望着我。于是我点击左上角返回键，然后继续搜索...\n\n这不是一件在国内很常见的事情吗，然后我继续浏览，点击一个百度百科网页链接，又是还没开看，appstore显示了出来，这次是百度百科app。\n\n好，没事，我平复了一下心情，整理了一下被打乱的思绪，继续浏览着百科，滑到页面底部，加载新的内容时，一个弹窗显示出来：使用百度百科APP，获取更好的浏览体验！\n\n关闭，继续浏览。\n\n点击百科内部的内链，尝试跳转到另一个百科界面，突然，浏览器一片空白，我又被引导向appstore。\n\n很抱歉，我直接关闭了百度，使用谷歌和维基百科继续查询资料。这一次，谷歌虽然也在下方提示【在IOS上尝试使用谷歌桌面版，获取更好的体验】，但至始至终没有把我强制跳到appstore。维基百科就更不用说了，连使用app都没有提示。\n\n退出了浏览器，我不禁陷入了沉思。我还记得不久前拿到朋友的新鸿蒙手机，划开屏幕一看，第一个界面全是百度系列：百度、百度搜索、百度智能浏览器、百度贴吧、百度知道...一个个功能冗余的百度app赫然显示在我的眼前，当我一脸震惊地看向朋友，他耸耸肩：点进去就自己下载的，不安装就没办法看了。\n\n看着自己苹果手机中的两个一个浏览器：Safari和Alook，我停止了思考，当一个大厂天天为自己的免费网盘带宽叫屈，下载一个3M的电子书被限成一副狗样时，你还能相信他有这么大的带宽给用户推自己的动辄100MB的APP？这能算是本末倒置吗？\n\n从此，我在手机上再也没有用过百度系。必应和谷歌，DogeDoge和DuckDuckGo成为了我的搜索主力。\n\n# 为什么是APP\n\n## 隐私\n\n\napp对隐私的疯狂到了什么地步？\n\n在安卓环境【尤其是国内某些套壳系统】下，app的权限不算小，有些时候可以在没有提醒的情况下把你的浏览器记录翻个遍。\n\nios其实相对安卓来说，至少系统能主动提醒用户是否给予其访问权利。\n\n这一点我也十分佩服MIUI，能在这种隐私岁随意获取风气下站住来守住用户的底线，无论其目的如何，这一点已经赢得了我的好感【虽然我不用安卓】\n\n对于软件商来说，用户的数据是一大笔财富。比如知道所有人的喜好、购买能力等，这些信息掌握得越细致，越能挖掘到更多的商机。\n\n暂且不说百度，就连TIM和QQ也会主动扫描用户Chrome浏览记录<span class=\"heimu\">~~我靠那我的nhentai浏览记录怎么办~~</span>\n\n## 互唤醒【For安卓】\n\n为了实现广告营销，部分软件实际上要向用户主动推送广告信息。\n\n尤其是安卓，由于谷歌市场退出中国大陆，国内安卓生态其实很乱，一个简单的消息推送，也能难倒一群开发者。\n\n为什么消息推送变成了一个难题？其实我们想象中的消息推送与实际上的方式有很大差距:\n\n想象中：用户手机<==主动推送==微信服务器\n实际上：用户手机<==被动推送==>苹果|安卓消息推送服务器<==主动推送==微信服务器\n\n苹果还好说，18年以前经常会出现微信无法推送的情况，但自从大陆线路优化以及云上贵州的迁移，其推送服务逐渐变得正常。然而谷歌早已退出中国市场，其内置的推送服务器已经不可链接，请问这些app这么办？\n\n答：常驻系统后台。\n\n但是常驻系统后台成为一个Zombine进程也不可避免会被杀掉，请问这又能怎么办？\n\n答：相互唤醒。\n\n当用户打开一个app，此app会在后台激活另一群app，然后如果当前app被杀了，被激活的app又会激活那个被杀的app。\n\n这样就很好理解了虽然只有百度app才会推送广告，但他依旧会引导你去下载百度浏览器---避免被杀掉啊。\n\n# 为什么不是浏览器应用\n\n## 隐私\n\n在这个隐私即金钱的时代，对于国内厂商来说，首先一个遗憾的事情是，浏览器是很难获取到用户的隐私信息。不是说功能限制，而是浏览器其核心就是沙盒化。在没有用户同意和外接接口、插件的前提下，你不可能直接用js获取到用户手机/电脑上的文件。\n\n而且最致命的是，如果网页应用敢在后台偷偷上传用户隐私，控制台一开就会使其暴露无遗，相对比APP的黑盒操作，那简直是天差地别。\n\n## 功能限制\n\njs功能其实很强大，但有些底层和协议上的限制不能做就是不能做，你不可能用js空手写一个SMTP发送邮件，你也不可能直接用SSH协议链接服务器【WebSSH需要在服务器主动安装服务端】\n\n其次，一些十分耗资源和计算力的服务不可能在浏览器上实现，比如腾讯不可能把王者荣耀搬到浏览器上，你也不可能在浏览器里跑机器学习。\n\n## 网络限制\n\n如果使用浏览器，其每一次打开服务网店都要重新下载上面的js、css和图片资源，这一瞬间爆发对服务器压力其实不小。\n\n而使用app，他可以事先在后台下载好广告图片，其样式和功能无需重新下载，并且很多资源可以缓存在本地，即使短暂离线也能推送。\n\n这一点，PWA技术完全可以胜任。PWA通过在浏览器内ServiceWorker拦截和缓存内容实现离线浏览。但目前来讲PWA技术在国内不温不火【很明显，触碰到了某些企业的利益】，所以还是以应用程序为主。\n\n<span class=\"heimu\">但是，你这样剩下来的流量费还是比不过强制更新来的多啊</span>\n\n# 为什么国外没有出现类似的情况\n\n## 监管缺失\n\n海外，安卓应用最官方的商店只有一家：GooglePlay，虽然不像AppStore那种不上架连安装都不给的程度，但也是一种象征。没有上架谷歌商店的应用基本都会被判定为盗版或者危险。而且谷歌play对广告监管很严。如果一个应用敢像百度般，疯狂推送广告和自唤醒，可能连安全审查都过不去。\n\n在国内，连老大都管不了，宛若袁世凯暴毙天下军阀混战，其乱象不言而喻。\n\n## 隐私意识缺乏\n\n李彦宏有句~~名言~~：中国人更愿意用隐私交换便捷性。\n\n虽然此话一出被无数网友嘲讽，但也不得不承认这确实如此。甚至有些时候自己也是被迫的。没有多少人会上网的时候开无数个虚拟机中继代理AdGuard，相反，有更多人为了PDD的几分钱蔬菜而抢破头。一句话：国人都喜欢薅羊毛，但最终都会成为韭菜被割。\n\n相反，在国外，人们对于隐私十分看重，哪怕GoogleAdsense都被罚了好几次，还不用说Tor之类的隐私保护软件。\n\n## 使用观念的不同\n\n我个人的习惯是，完成一件事情，用什么东西都越轻越好，不是有必要就不下客户端。比如在电脑微信接收消息，你可以选择下载微信客户端完成传输，也可以用[网页微信](https://wx.qq.com)。相较于前者，后者用完就关，不留痕迹，速度也快。\n\n然而国人的习惯大多是：先下载下来，万一以后有用呢。\n\n当我看到电视上的手机广告，大多8H16G运存128G内存起步，盯着手里这台国产只装了QQ到2021年还能打Minecraft的iPhone6s【实际配置2GB运存A9处理器】，不禁留下了悔恨的泪水：幸好没买安卓。\n\n安卓手机即使内存再大，其底层核心还是虚拟化，加上国内的恶劣的生态，如果你不留神多下点软件，其流畅度甚至比不过6年前的6s。\n\n而手机卡，大多数人的第一个想法是：换一台手机。而不是：我删掉点软件，只保留QQ和微信。\n\n尤其是，在国内的内循环已经完成的前提下，更多人选择了买爱国手机，装爱国软件。实际上，留一条隐私底线其实也没有什么。但偏偏有人喜欢把自己隐私送给别人。\n\n# 后言\n\n实际上，绝大多数软件从C/S架构向B/S架构的转换是不可避免的。但是国内的生态似乎在阻碍着这一发展。\n\n或许有人会问，隐私再保护有什么用。那我只能说，如果你的隐私在黑市只能卖1毛钱一条，那隐私保护的好的人或许能卖5块钱一条。真正的危害其实不在于精准推送，而更怕有人会拿去做违法事情，暴力你，诈骗你。","tags":["应用","浏览器","隐私","app"],"categories":["叨叨念"]}]