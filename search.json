[{"title":"SpeedUp!使用黑科技为你的网站提速","url":"/p/d3c51290.html","content":"\n实战，利用黑科技ServiceWorker提速你的网站。\n\n<!--more-->\n\n\n> 本文所标记的内容，大多是直接复制粘贴即可实现的。但依然会存在这和您的服务存在冲突这一情况。请阅读上一篇基础文章[欲善其事，必利其器 - 论如何善用ServiceWorker](/p/c0af86bb.html)进行合理的修改。\n\n\n我们简单的列一下表，这是我们加速清单：\n\n\n- [分离资源，静态加速](#前端竞速CDN)\n- [加速主网页](#全站NPM静态化)\n- [调剂响应](#调剂响应)\n- [首屏加速](#优化首屏)\n\n# 前端竞速CDN\n\n最传统的网页加载，其静态资源一旦独立是直接放在同域服务器下的。\n\n不过后来，为了减少主服务器开销，我们通常将静态资分离至其他面向用户加载比较快的节点，以减少主服务器开销，提升网页加载速度。\n\n现在，各种公益cdn服务蓬勃生长，其节点通常是全球部署，并且对各个国家/地区做了优化，使用公益cdn，他的质量和可用性是远远大于自己部署的。\n\n在一个网页加载中，主网页只提供一个html（你所看的网页其大小约`15kb`），而流量开销巨头是静态资源（只论js，本页大约`800kb`）。我们对一个网站的加速，第一步就应当从静态加速做起。\n\n对于加速存储的选择，通常市面上有三种主流加速`cdnjs`/`npm`/`gh`。而在这其中，对于个人而言，我还是推崇`npm`，这在接下来对于竞速节点的选择就多了起来。\n\n对于加速节点的选择，从mainland角度来讲，首先你要遵循一个普世结论：`不要用跨国节点`。本身China国度就有个奇葩规定，没有ICP备案许可就不得在mainland开展网站服务。这使得大部分本应该分散在边缘末端的流量全压到了国际出口的汇聚层。你再引导他们去海外拉资源，凑过去挤热闹，其稳定性和速率完全无法保证，这在生产环境使用无异于自杀。这里提一嘴jsdelivr，备案掉了，节点迁出中国了，那你面向国内的网站早就可以切了。使用fastly，联通和电信晚上ntt几乎堵到妈都不认识，能连上就是奇迹。除非你真的不在意加速，也不在意资源能不能正常加载，在面向mainland的生产环境里还坚持jsd就是愚不可及的行为。\n\n当然，在这里我还是推崇黑科技`ServiceWorker`，它可以利用`Promise.any`，并发数个请求至不同的cdn节点，提升前端资源加载。而借助于强大的js引擎，其在本地处理的效率奇高，性能折损几乎不计。\n\n在这之前，我们定义一个`lfetch`，它的作用是对`urls`这个数组里的所有网址发起并发请求，并且在任意一个节点返回正常值时**打断**其余请求，避免流量浪费。\n\n```js\nconst lfetch = async (urls, url) => {\n    let controller = new AbortController(); //针对此次请求新建一个AbortController,用于打断并发的其余请求\n    const PauseProgress = async (res) => {\n        //这个函数的作用时阻塞响应,直到主体被完整下载,避免被提前打断\n        return new Response(await (res).arrayBuffer(), { status: res.status, headers: res.headers });\n    };\n    if (!Promise.any) { //Polyfill,避免Promise.any不存在,无需关注\n        Promise.any = function (promises) {\n            return new Promise((resolve, reject) => {\n                promises = Array.isArray(promises) ? promises : []\n                let len = promises.length\n                let errs = []\n                if (len === 0) return reject(new AggregateError('All promises were rejected'))\n                promises.forEach((promise) => {\n                    promise.then(value => {\n                        resolve(value)\n                    }, err => {\n                        len--\n                        errs.push(err)\n                        if (len === 0) {\n                            reject(new AggregateError(errs))\n                        }\n                    })\n                })\n            })\n        }\n    }\n    return Promise.any(urls.map(urls => {//并发请求\n        return new Promise((resolve, reject) => {\n            fetch(urls, {\n                signal: controller.signal//设置打断点\n            })\n                .then(PauseProgress)//阻塞当前响应直到下载完成\n                .then(res => {\n                    if (res.status == 200) {\n                        controller.abort()//打断其余响应(同时也打断了自己的,但本身自己已下载完成,打断无效)\n                        resolve(res)//返回\n                    } else {\n                        reject(res)\n                    }\n                })\n        })\n    }))\n}\n```\n\n在这其中，有一个难点：`fetch`返回的时状态而非内容。\n即当`fetch`的`Promise resolve`时，它是已经获得了响应，但此时内容还没下载，提前打断会导致无法返回。这是`PauseProgress`作用。\n\n之后我们考虑静态资源加速。这时候用npm的好处就体现出来了，不仅镜像多，其格式也还算固定。\n\n\n> 注意，此方法是以流量换速度的方式进行的，虽然在任何一个节点返回正确内容后会打断其余请求，但依然会造成不可避免的流量消耗(+~20%)。如果你面向的是手机流量用户，请三思而后行！\n\n> 此代码与[freecdn-js](https://github.com/EtherDream/freecdn-js)核心功能相似，但实现方法并不同，并且完全支持动态网页。\n\n例如jquery，你可以这样加速：\n\n```\n原始地址:\nhttps://cdn.jsdelivr.net/npm/jquery@3.6.0\n各类镜像：\nhttps://fastly.jsdelivr.net/npm/jquery@3.6.0\nhttps://gcore.jsdelivr.net/npm/jquery@3.6.0\nhttps://unpkg.com/jquery@3.6.0\nhttps://unpkg.zhimg.com/jquery@3.6.0 #回源有问题\nhttps://unpkg.com/jquery@3.6.0\nhttps://npm.elemecdn.com/jquery@3.6.0\nhttps://npm.sourcegcdn.com/jquery@3.6.0 #滥用封仓库\nhttps://cdn1.tianli0.top/jquery@3.6.0 #滥用封仓库\n```\n\n我们可以简单搓一个sw小脚本完成前端加速：\n\n\n<details class=\"about\">\n    <summary>ServiceWorker完整代码：</summary>\n   <details>\n    <summary>我已经很详细的看了上面的阐述，并且我不会直接照搬</summary>\n\n```js\nconst CACHE_NAME = 'ICDNCache';\nlet cachelist = [];\nself.addEventListener('install', async function (installEvent) {\n    self.skipWaiting();\n    installEvent.waitUntil(\n        caches.open(CACHE_NAME)\n            .then(function (cache) {\n                console.log('Opened cache');\n                return cache.addAll(cachelist);\n            })\n    );\n});\nself.addEventListener('fetch', async event => {\n    try {\n        event.respondWith(handle(event.request))\n    } catch (msg) {\n        event.respondWith(handleerr(event.request, msg))\n    }\n});\nconst handleerr = async (req, msg) => {\n    return new Response(`<h1>CDN分流器遇到了致命错误</h1>\n    <b>${msg}</b>`, { headers: { \"content-type\": \"text/html; charset=utf-8\" } })\n}\nlet cdn = {//镜像列表\n    \"gh\": {\n        jsdelivr: {\n            \"url\": \"https://cdn.jsdelivr.net/gh\"\n        },\n        jsdelivr_fastly: {\n            \"url\": \"https://fastly.jsdelivr.net/gh\"\n        },\n        jsdelivr_gcore: {\n            \"url\": \"https://gcore.jsdelivr.net/gh\"\n        }\n    },\n    \"combine\": {\n        jsdelivr: {\n            \"url\": \"https://cdn.jsdelivr.net/combine\"\n        },\n        jsdelivr_fastly: {\n            \"url\": \"https://fastly.jsdelivr.net/combine\"\n        },\n        jsdelivr_gcore: {\n            \"url\": \"https://gcore.jsdelivr.net/combine\"\n        }\n    },\n    \"npm\": {\n        eleme: {\n            \"url\": \"https://npm.elemecdn.com\"\n        },\n        jsdelivr: {\n            \"url\": \"https://cdn.jsdelivr.net/npm\"\n        },\n        zhimg: {\n            \"url\": \"https://unpkg.zhimg.com\"\n        },\n        unpkg: {\n            \"url\": \"https://unpkg.com\"\n        },\n        bdstatic: {\n            \"url\": \"https://code.bdstatic.com/npm\"\n        },\n        tianli: {\n            \"url\": \"https://cdn1.tianli0.top/npm\"\n        },\n        sourcegcdn: {\n            \"url\": \"https://npm.sourcegcdn.com/npm\"\n        }\n\n    }\n}\n//主控函数\nconst handle = async function (req) {\n    const urlStr = req.url\n    const domain = (urlStr.split('/'))[2]\n    let urls = []\n    for (let i in cdn) {\n        for (let j in cdn[i]) {\n            if (domain == cdn[i][j].url.split('https://')[1].split('/')[0] && urlStr.match(cdn[i][j].url)) {\n                urls = []\n                for (let k in cdn[i]) {\n                    urls.push(urlStr.replace(cdn[i][j].url, cdn[i][k].url))\n                }\n                if (urlStr.indexOf('@latest/') > -1) {\n                    return lfetch(urls, urlStr)\n                } else {\n                    return caches.match(req).then(function (resp) {\n                        return resp || lfetch(urls, urlStr).then(function (res) {\n                            return caches.open(CACHE_NAME).then(function (cache) {\n                                cache.put(req, res.clone());\n                                return res;\n                            });\n                        });\n                    })\n                }\n            }\n        }\n    }\n    return fetch(req)\n}\nconst lfetch = async (urls, url) => {\n    let controller = new AbortController();\n    const PauseProgress = async (res) => {\n        return new Response(await (res).arrayBuffer(), { status: res.status, headers: res.headers });\n    };\n    if (!Promise.any) {\n        Promise.any = function (promises) {\n            return new Promise((resolve, reject) => {\n                promises = Array.isArray(promises) ? promises : []\n                let len = promises.length\n                let errs = []\n                if (len === 0) return reject(new AggregateError('All promises were rejected'))\n                promises.forEach((promise) => {\n                    promise.then(value => {\n                        resolve(value)\n                    }, err => {\n                        len--\n                        errs.push(err)\n                        if (len === 0) {\n                            reject(new AggregateError(errs))\n                        }\n                    })\n                })\n            })\n        }\n    }\n    return Promise.any(urls.map(urls => {\n        return new Promise((resolve, reject) => {\n            fetch(urls, {\n                signal: controller.signal\n            })\n                .then(PauseProgress)\n                .then(res => {\n                    if (res.status == 200) {\n                        controller.abort();\n                        resolve(res)\n                    } else {\n                        reject(res)\n                    }\n                })\n        })\n    }))\n}\n```\n</details>\n</details>\n\n\n\n\n# 全站NPM静态化\n\n> 此法chen独创，是一种比较野路子的手法，但加速效果显著。\n> 通常建议用于Hexo等静态博客，WordPress等需要做好伪静态，并且要配置好动态接口。\n\nhexo作为静态博客有什么好处，那当然是纯静态啦。生成的静态文件随便搬到一个web服务器都能用。\n\n自然就有了接下的骚操作，用npm托管博客，然后在请求的时候用sw劫持并引流到npm镜像，效果就如同本博客所示，加载速度（抛开首屏不谈）接近于闪开。\n\n首先我博客的CI是用GithubAction的，在部署的过程中顺便把html上传到npm是最简单不过的事情，只要在生成代码块后面再加一块：\n\n```yml\n- uses: JS-DevTools/npm-publish@v1\n  with:\n    token: ${{ secrets.NPM }}\n```\n\n配置`NPM`环境变量，之后需要更新的时候叠一个新版本就行。\n\n然后接下来我们就要解决ServiceWorker获取问题。我们先设立一个监听器：\n\n```javascript\nself.addEventListener('fetch', async event => {\n    event.respondWith(handle(event.request))\n});\nconst handle = async(req)=>{\n    const urlStr = req.url\n    const urlObj = new URL(urlStr);\n    const urlPath = urlObj.pathname;\n    const domain = urlObj.hostname;\n    //从这里开始\n}\n```\n\n首先我们要判断一下这个域名是不是博客主域名,不然瞎拦截到其他地方可不好:\n\n```js\nif(domain === \"blog.cyfan.top\"){//这里写你需要拦截的域名\n    //从这里开始处理\n}\n```\n\n我们还要记得给url进行提前处理，剥离出路径，去除参数。在这其中尤其要注意的是默认路由的处理。\n\n通常情况下我们访问一个网址，web服务器会在后面添加`.html`后缀。对于一个默认路径则是`index.html`。\n\n还要注意的是剥离`#`，不然又会获取失败。\n\n定义一个`fullpath`函数，用于预处理和剥离路径：\n\n```js\nconst fullpath = (path) => {\n    path = path.split('?')[0].split('#')[0]\n    if (path.match(/\\/$/)) {\n        path += 'index'\n    }\n    if (!path.match(/\\.[a-zA-Z]+$/)) {\n        path += '.html'\n    }\n    return path\n}\n```\n\n结果类似于：\n\n```\n> fullpath('/')\n'/index.html'\n> fullpath('/p/1')\n'/p/1.html'\n> fullpath('/p/1?q=1234')\n'/p/1.html'\n> fullpath('/p/1.html#QWERT')\n'/p/1.html'\n```\n\n然后再定义一个镜像并发函数，用于生成待获取的网址：\n\n```js\nconst generate_blog_urls = (packagename, blogversion, path) => {\n    const npmmirror = [\n        `https://unpkg.com/${packagename}@${blogversion}/public`,\n        `https://npm.elemecdn.com/${packagename}@${blogversion}/public`,\n        `https://cdn.jsdelivr.net/npm/${packagename}@${blogversion}/public`,\n        `https://npm.sourcegcdn.com/npm/${packagename}@${blogversion}/public`,\n        `https://cdn1.tianli0.top/npm/${packagename}@${blogversion}/public`\n    ]\n    for (var i in npmmirror) {\n        npmmirror[i] += path\n    }\n    return npmmirror\n}\n```\n\n\n接下来我们将其填入主路由中:\n\n```js\nif(domain === \"blog.cyfan.top\"){//这里写你需要拦截的域名\n    return lfetch(generate_blog_urls('chenyfan-blog','1.1.4',fullpath(urlPath)))\n}\n```\n\n然而谨记,npm返回的文件格式通常是text而非html，所以我们还要进一步处理header。处理也简单，连环then下去就行：\n\n```js\nif(domain === \"blog.cyfan.top\"){\n    return lfetch(generate_blog_urls('chenyfan-blog','1.1.4',fullpath(urlPath)))\n    .then(res=>res.arrayBuffer())//arrayBuffer最科学也是最快的返回\n    .then(buffer=>new Response(buffer,{headers:{\"Content-Type\":\"text/html;charset=utf-8\"}}))//重新定义header\n}\n```\n\n那么接下来，除了首屏以外，你的网站相当于托管在全球(包括中国)各个主流cdn服务器中，提速效果无与伦比.如果你将原网站托管在cf，那么你将获得一个打不死，国内加载速度超快(首屏除外)的网站。\n\n## 解放双手 - npm版本自定义更新\n\n有人会问了，我为什么不能直接用latest来获取最新版本，还要手动指定？\n\n简单地说，在生产环境中用@latest指定最新版本是一个很不合理、且非常愚蠢的操作。你永远都不知道对面的缓存什么时候清除，获取到的可能是一年前的版本。\n\n为了节约成本，避免回源，cdn服务商通常会缓存资源，尤其是那些静态资源。以jsd为例，其latest缓存为7天，不过可以手动刷新。unpkg cf边缘2星期，eleme已经将近6个月没更新了。至于那些自建的。你根本搞不懂他什么时候更新，使用latest会导致随机获取到版本，接近无法正常使用。\n\n而指定版本的，cdn通常会永久缓存。毕竟版本定死了东西是不会变的，而请求指定版本的cdn也可以或多或少提升访问速度，因为文件时永久缓存的，HIT的热度比较高。\n\n### sw端\n\n利用npm registry获取最新版本，其官方endpoint如下：\n\n```url\nhttps://registry.npmjs.org/chenyfan-blog/latest\n```\n\n其version字段即最新版本。\n\nnpm registry的镜像也不少，以腾讯/阿里为例：\n\n```url\nhttps://registry.npmmirror.com/chenyfan/latest #阿里，可手动同步\nhttps://mirrors.cloud.tencent.com/npm/chenyfan/latest #腾讯，每日凌晨同步\n```\n\n获取最新版本也不难:\n\n```js\nconst mirror = [\n        `https://registry.npmmirror.com/chenyfan-blog/latest`,\n        `https://registry.npmjs.org/chenyfan-blog/latest`,\n        `https://mirrors.cloud.tencent.com/npm/chenyfan-blog/latest`\n]\nconst get_newest_version = async (mirror) => {\n    return lfetch(mirror, mirror[0])\n        .then(res => res.json())\n        .then(res.version)\n}\n```\n\n在这里还有一个坑点：ServiceWorker的全局变量会在所有页面关闭后销毁。下次启动时会优先响应handle，其定义变量要在handle响应后才会执行。因此，对于最新版本的存储，不能直接定义变量，需要持久化，这里另辟蹊径，采用CacheStorage存储：\n\n\n```js\nself.db = { //全局定义db,只要read和write,看不懂可以略过\n    read: (key, config) => {\n        if (!config) { config = { type: \"text\" } }\n        return new Promise((resolve, reject) => {\n            caches.open(CACHE_NAME).then(cache => {\n                cache.match(new Request(`https://LOCALCACHE/${encodeURIComponent(key)}`)).then(function (res) {\n                    if (!res) resolve(null)\n                    res.text().then(text => resolve(text))\n                }).catch(() => {\n                    resolve(null)\n                })\n            })\n        })\n    },\n    write: (key, value) => {\n        return new Promise((resolve, reject) => {\n            caches.open(CACHE_NAME).then(function (cache) {\n                cache.put(new Request(`https://LOCALCACHE/${encodeURIComponent(key)}`), new Response(value));\n                resolve()\n            }).catch(() => {\n                reject()\n            })\n        })\n    }\n}\n\nconst set_newest_version = async (mirror) => { //改为最新版本写入数据库\n    return lfetch(mirror, mirror[0])\n        .then(res => res.json()) //JSON Parse\n        .then(async res => {\n            await db.write('blog_version', res.version) //写入\n            return;\n        })\n}\n\nsetInterval(async() => {\n    await set_newest_version(mirror) //定时更新,一分钟一次\n}, 60*1000);\n\nsetTimeout(async() => { \n    await set_newest_version(mirror)//打开五秒后更新,避免堵塞\n},5000)\n```\n\n再将上面的生成urls从:\n\n```js\ngenerate_blog_urls('chenyfan-blog','1.1.4',fullpath(urlPath))\n```\n\n改为\n\n```js\n//若第一次没有,则使用初始版本1.1.4,或者你也可以改成latest(不推荐)\ngenerate_blog_urls('chenyfan-blog',await db.read('blog_version') || '1.1.4',fullpath(urlPath))\n```\n\n此后用户加载时，会尽可能的获取最新版本，无需手动更新。\n\n### ci端\n\n有了前端自动更新，我们在上传包的时候还要手动更新`package.json`中的version字段。其实这里也可以直接交给ci处理。\n\n然而需要注意，`npm version patch` 虽然能更新z位数版本，但其更新不会上传到仓库。换句话说，这只能上传一次。因此这个地方我干脆建议用随机数，反正通过api获得的latest都是最新的上传。\n\n案例代码这里不展示，实际上这一步做起来也不难。\n\n\n# 调剂响应\n\n## 缓存 - 互联网上一伟大发明\n\n> 虽然我也不清楚有一小部分人对那么丁点CacheStorage缓存占用那么敏感，但至少，缓存对网站加载速度的提升有极大的帮助。\n\n通常，有大量的资源是访问一个网站重复需要的，对于这些东西，浏览器会自带MemoryCache或DiskCache，但这一类缓存不是持久的，在下一次打开网站的时候缓存不一定生效。而CacheStorage是浏览器自带的缓存桶（Key/Value），这种桶是持久存储，长期有效，而sw是能控制这桶。\n\n而不同的网域资源所应当采取的缓存策略也是不一样的。对于确定版本的静态资源，直接终生缓存；对于有时限的静态资源，应当不缓存或只缓存一小段时间。\n\nCacheStorage不是sw专属的，你可以在前端和sw中同时控制它，这是几分样例代码：\n\n```js\nconst CACHE_NAME = 'cache-v1'; //定义缓存桶名称\ncaches.open(CACHE_NAME).then(async function (cache) {\n    const KEYNAME = new Request('https://example.com/1.xxx') //定义KEY，[Object Request]\n    await cache.put(KEYNAME, new Response('Hello World')); //自定义填入\n    await cache.match(KEYNAME).then(async function (response) {\n        console.log(await response.text()); //匹配并输出\n    })\n    await cache.put(KEYNAME, await fetch('https://example.com/2.xxx').then(res=>res.arrayBuffer())); //使用fetch填入缓存\n    await cache.matchAll().then(function (responses) { //列出所有（也可以根据内容列出指定的项\n        for (let response of responses) {\n            console.log(response.url);\n        }\n    })\n    await cache.delete(KEYNAME) //删除指定项\n});\n```\n\n## SetTimeout - 毫秒级调控响应\n\n对于同一个网页，你需要合理的对他执行决策树，这是目前我的博客[网页]采取的决策树:\n\n![](https://npm.elemecdn.com/chenyfan-os@0.0.0-r18/1.png)\n\njs里有两个对时间控制的古老函数：`SetTimeout`和`SetInterval`.在这里我采用`SetTimeout`,同时并行执行任务.\n\n这里采用代码片段比较容易解释:\n\n```js\nif (请求的网址是博客) {\n    //这里一定要用Promise,这样在之后settimeout就不需要回调,直接Resolve\n    return new Promise(function (resolve, reject) {\n        setTimeout(async () => {\n            if (存在缓存) {\n                setTimeout(() => {\n                    resolve(获取当前页面缓存(请求))\n                }, 200);//200ms表示下面的拉取失败后直接返回缓存,但下面的拉取不会被踢出,更新会在后台执行,会填入缓存,但也不会返回\n                setTimeout(() => {\n                    resolve(\n                        拉取最新版本的网页(请求)\n                            .then(填入缓存并返回内容)//返回缓存\n                    )\n                }, 0);//表示立刻执行,优先级最高\n            } else {\n                setTimeout(() => {\n                    resolve(\n                        拉取最新版本的网页(请求)\n                            .then(填入缓存并返回内容)//返回缓存\n                    )\n                }, 0);//表示立刻执行,优先级最高\n\n                setTimeout(() => {\n                    resolve(返回错误提示())\n                }, 5000)//5000ms后如果没有返回最新内容就直接返回错误提示,如果成功了此次返回是无效的\n            }\n        }, 0)//这里需要一个大settimeout包裹以便于踢出主线程,否则无法并行处理\n\n    })\n}\n```\n\n# 优化首屏\n\n## window.stop - 与死神擦肩而过\n\n事实上，ServiceWorker最显著的缺点是要在第一次加载网页安装后，刷新一次才能激活。即访客第一次访问是不受sw控制的。换句话说，访客首屏不受加速，其加载速度与你的服务器有直接联系 ~~[虽然安装完成后就起飞了,但安装前就是屑]~~。\n\n而本人未成年，浙江的规定又是未成年不得备案，在加上之后备案主题切换异常的麻烦。我的决定是至少高考前都不会备案。那这后果就很直接，我并不能使用国内的cdn节点。再加上我又没这个经济实力用香港CN2或拉iplc专线，对首屏服务器这一块优化其实能做的很少。\n\n更加令人抓狂的是，在首屏加载时，静态资源会被直接获取，并且不缓存，而sw激活后又会强制第二次获取，拉跨速度。\n\n不过我们可以尽可能弱化这一劣势。我们可以用js打断所有的请求，以确保首屏只加载一个html和一个sw.js，其余资源都不会加载，降低首屏加载延迟。\n\n我们尽可能将打断代码提到`<head>` 以确保不被其他资源堵塞，对于hexo来说打开主题的`head.ejs`，在`<head>`标签靠前的位置中加入：\n\n```js\n(async () => {//使用匿名函数确保body已载入\n    /*\n    ChenBlogHelper_Set 存储在LocalStorage中,用于指示sw安装状态\n    0 或不存在 未安装\n    1 已打断\n    2 已安装\n    3 已激活,并且已缓存必要的文件(此处未写出,无需理会)\n    */\n    const $ = document.querySelector.bind(document);//语法糖\n    if ('serviceWorker' in navigator) { //如果支持sw\n        if (Number(window.localStorage.getItem('ChenBlogHelper_Set')) < 1) {\n            window.localStorage.setItem('ChenBlogHelper_Set', 1)\n            window.stop()\n            document.write('Wait')\n        }\n        navigator.serviceWorker.register(`/sw.js?time=${ranN(1, 88888888888888888888)}`)//随机数,强制更新\n            .then(async () => {\n                if (Number(window.localStorage.getItem('ChenBlogHelper_Set')) < 2) {\n                    setTimeout(() => {\n                        window.localStorage.setItem('ChenBlogHelper_Set', 2)\n                        //window.location.search = `?time=${ranN(1, 88888888888888888888)}` //已弃用,在等待500ms安装成功后直接刷新没有问题\n                        window.location.reload()//刷新,以载入sw\n                    }, 500)//安装后等待500ms使其激活\n                }\n            })\n            .catch(err => console.error(`ChenBlogHelperError:${err}`))\n    }\n})()\n```\n\n当然了，这回导致白屏500ms，如果你觉得不好看，也可以和我一样载入一个等待界面，将`document.write()`改为:\n\n```js\ndocument.body.innerHTML = await (await fetch('https://npm.elemecdn.com/chenyfan-blog@1.0.13/public/notice.html')).text()\n```\n\n即可\n\n![](https://npm.elemecdn.com/chenyfan-os@0.0.0-r18/2.png)\n\n\n## 主服务器优化 - 绝望中的最后一根稻草\n\n实际上我一直以为，主服务器的优化在整个网站中是最必要的，也是最不重要的。必要的原因是它关系到最初的加载速度，也是访客中最主要的一环；不重要的是相对于静态资源的记载、页面的渲染和脚本的编译，首屏的加载对整体效果太小了。\n\n尤其是在sw托管后，之后的所有访问，除了sw的更新（以及所有镜像源全炸后），基本与主服务器脱离了关系，正常访问与其没有关系。加速源站实则没有必要。\n\n当然，你说有用吗，那肯定还有点用处，至少首次加载不至于卡人心态。我的要求很简单，能在600ms内完成首次html下载的基本就没问题了。\n最优的无非是香港CN2，不过我们没这个能力。退而求其次，普通的香港服务器我们也能接受。不过依旧是白嫖至上的念头，我才用了Vercel。Vercel也是可以自选节点（主要是亚马逊和谷歌）的，我稍加测试【主要注重可连接性，其次是延迟。丢包和速度作为建站（尤其只有一个10kb的网页）最次】，决定使用一下策略：\n\n```\n电信 104.199.217.228 【台北 谷歌Cloud】 70ms （绕新加坡 但是是质量最好的）\n联通 18.178.194.147 【日本 亚马逊】 45ms （4837和aws在tyo互联）\n移动 18.162.37.140 【香港 谷歌Cloud】 60ms （移动去香港总是最好的选择）\n```\n\n在这里，不推荐其他地区的理由是：\n\n电信：基本上除了台北，去GoogleCloud的都是走日本ntt × ； 亚马逊这一块有大部分绕美，去日本延迟异常的大。\n联通：去香港的绕美了，去日本这一条存在这直接的互联点，负载比较小，延迟也不错。\n移动：没什么好说的，移动互联除了去亚太的都是垃圾。\n\n# 后记\n\n一张思维导图总结全文，你学废了吗？\n\n![](https://npm.elemecdn.com/chenyfan-os@0.0.0-r18/3.png)\n","tags":["ServiceWorker","黑科技"],"categories":["随心扯"]},{"title":"欲善其事，必利其器 - 论如何善用ServiceWorker","url":"/p/c0af86bb.html","content":"\nServiceWorker作为前端革命领袖，毫不夸张地被誉为前端黑科技，此文将阐述如何巧妙的使用它来实现一些看起来匪夷所思的事情。\n\n<!--more-->\n\n> **Warning**\n> 此文为最基本的SW使用基础,如果你只是想来白嫖代码的建议退出选择下一篇实操文章.\n\n# 起因 - 巨厦坍塌\n\n2021/12/20日，赶在旧年的末尾，一则`JSdelivrSSL证书错误`缓缓上了v2ex论坛热点。\n\n此前JSD由于各种原因,曾经不正常了一段时间,所以大家并未对此感冒.正当人们以为这只是JSdelivr每年一度的`年经`阵痛,发个issue,过一段时间就好了的时候.官方直接爆出大料:**JSDelivr had lost their ICP license**\n\n由此可见,过去的几年里,当人们发现JSD对个人面向国内加速拥有者无与伦比的效果时,各种滥用方式层出不穷:图床曾一阵流行,国内搜索引擎JSdelivr十有八九都是作为图床的,连PicGo插件都出了Github+JSdelivr图床;猛一点的,直接做视频床,甚至为了突破单文件20M限制开发了一套ts切片m3u8一条龙服务;作妖的,托管了不少突破网络审查的脚本和规则集;寻死的,添加了大量的政治宗教敏感,有些甚至不配称为宗教,直接上来就是骗钱的.\n\njsd并不是没有发布许可条款，但这并不能阻止白嫖大军的进程。在羊毛大军中，只要是你是免费的、公益的，你就要做好被薅爆的结果。但是薅羊毛的前提是羊还活着，倘若羊被薅死了，哪来的羊毛给诸君所薅？\n\n总之，不管怎样，JSDelivr在决定将节点设置为`NearChina`，可以肯定的是，在最近很长一段时间内，我们都无法享受国内外双料同时加速的快感，换句话说，jsd在中国就被永久地打入了冷宫。\n\n视线转向国内，jsd的替代品并不少。早在我写[图床的千层套路](https://blog.cyfan.top/p/eb490c73.html)我就试着假想jsd不可用时，我们该用什么。最终我给出的一份较为完美的答案-npm图床，优点无非就是镜像多速度快，许可条款较为宽松，缺点也很明显，需要安装node，用专门的客户端上传。\n\n那事情就逐渐变得扑朔迷离起来了，我们应当如何选择合理的CDN加速器呢。\n\n这时候，我想起了前端黑科技Serviceworker。是的，这种情况下使用SW最为巧妙不过，它可以在后台自动优选最佳的CDN，甚至可以用黑中黑`Promise.any`打出一套漂亮的并行拳。经过两天的完善，我终于写出了一套具有离线可达、绕备、优选CDN、跟踪统计合一的SW脚本。[此博客使用的SW](/sw.js)\n\n接下来我将从头开始讲述ServiceWorker的妙用。\n\n# Before Start\n\n## What Is The ServiceWorker\n\n网上对于SW的解释比较模糊，在这里，我将其定义为`用户浏览器里的服务器`，功能强大到令人发指。是的，接下来的两张图你应该能显著的看到这一差距：\n\n![没有ServiceWorker中继，平淡无奇](https://npm.elemecdn.com/chenyfan-os@0.0.0-r5/1.jpg)\n\n![ServiceWorker中继，刺激拉满](https://npm.elemecdn.com/chenyfan-os@0.0.0-r5/2.jpg)\n\n在第一张图中，用户和服务器的关系直的就像电线杆，用户想要什么，服务器就还给他什么。\n\n第二张图中，用户在被ServiceWorker控制的页面中，无论向哪个服务器发起请求，其过程都会被SW捕获，SW可以仿佛不存在一般单纯地请求服务器，返回原本应该返回的内容【透明代理】；也可以对当前服务器返回的内容进行随意的捏造、修改【请求修改结果】；甚至可以将请求指向完全另一台服务器，返回不是此服务器应该返回的内容【移花接木】；当然，SW也可以直接返回已经存储在本地的文件，甚至离线的时候也能返回【离线访问可达性】。\n\n由于SW对于用户页面的操纵实在过于强大，因此，它被设计成`不可跨域请求`、`SW脚本必须在同一域名下`、`必须在HTTPS条件下运行`、`不可操纵DOM和BOM`，同样的，为了避免阻塞和延迟，SW也被特意设计成`完全异步的`。这些点将会在后面一一讲述。\n\n> 当然，开发者至上，为了方便本地调试，本机地址`localhost`和`127.0.0.1`被浏览器所信任，允许以`非HTTPS`方式运行serviceworker。\n\n## What Relationship Between ServiceWorker and PWA\n\n很多人看到sw，第一反应是PWA，即渐进式Web应用。实际上，SW确实是PWA的核心与灵魂，但SW在PWA中起的主要作用是缓存文件，提供给离线访问。并没有完整地发挥出SW的巧妙用法。\n\nSW可以完全脱离PWA存在，当然，PWA可离不开SW ：）\n\n## And WorkBox ?\n\nWorkBox是谷歌开发的一款基于SW的缓存控制器，其主要目的是方便维护PWA。核心依旧是SW，但还是没有SW原本的自定义程度高（\n\n## Why Not WorkBox ?\n\n首先，博客呢，是没有必要用PWA，有SW做中间件足矣。同时，WorkBox只能简单的缓存数据，并不能做到拦截篡改请求的功能，尤其不能精准把握每一个资源的缓存情况，自定义程度并不高。\n\n~~自己编写SW，格局就打开了~~\n\n# Start From Zero\n\n## 安装 / Install\n\n首先，SW的本质是JS脚本，要安装它必须要经过一个html。毕竟，只有拿到了html，JS才能运行于DOM上下文。\n\n剥离层层加成，安装的代码只有一行\n\n```JavaScript\nnavigator.serviceWorker.register('/sw.js')\n```\n\n其中，`/sw.js`即为ServiceWorker脚本所在，由于安全性，你不能加载跨域的SW。\n\n例如，当前网页为`https://blog.cyfan.top`，以下加载位置是允许的\n\n```url\n/sw.js\nhttps://blog.cyfan.top/sw.js\n```\n\n以下加载是不允许的:\n\n```url\nhttp://blog.cyfan.top/sw.js#非HTTPS\nhttps://cyfan.top/sw.js#非同一域名，视为跨域\nhttps://119.91.80.151:59996/sw.js#虽然为同一文件,但非同一域名，视为跨域\n./sw.js#容易造成SW脚本获取路径不一致\n```\n\n在加载前，我们最好判断一下dom是否加载完了，不然安装sw可能会卡dom\n\n加载完成后，register函数将返回一个`Promise`，由于前端大多不适用于`异步`，我们通常以`同步`的方式`.then()`和`.catch()`来获取是否加载成功。\n\n为了方便判断脚本是否能够加载，我们还要判断navigator里有无sw这一属性`'serviceWorker' in navigator`。\n\n由于SW安装后，页面需要刷新后才能交给SW所宰割，同时为了避免浏览器缓存的影响，我通常采用修改`search`的方式强刷新，而不是通过`reload`函数。同样的，为了避免刚安装完就刷新的尴尬感，建议用`setTimeout`延迟一秒刷新。\n\n简易的完整安装代码如下:\n\n```html\n<script>\nwindow.addEventListener('load', async () => {\n    navigator.serviceWorker.register(`/sw.js?time=${new Date().getTime()}`)\n        .then(async reg => {\n            //安装成功，建议此处强刷新以立刻执行SW\n            if (window.localStorage.getItem('install') != 'true') {\n                window.localStorage.setItem('install', 'true');\n                setTimeout(() => {\n                    window.location.search = `?time=${new Date().getTime()}`\n                }, 1000)\n            }\n        }).catch(err => {\n            //安装失败，错误信息会由err传参\n        })\n});\n</script>\n```\n\n一刷新，世界就变成了ServiceWorker的瓮中之鳖，接下来，该是SW脚本正式登场的时候了。\n\n## SW安装初始化 / Installations\n\n首先，先尴尬的开一个空缓存列表：\n\n```js\nconst CACHE_NAME = 'ICDNCache';//可以为Cache版本号，但这样可能会导致缓存冗余累积\nlet cachelist = [];\n```\n\n`cachelist`里面填写的是预缓存网址，例如在离线时返回的错误页面。此处不宜添加过多网址，此处点名@一下Akilar。\n\n此处我建议只缓存离线页面展示的内容:\n\n```js\nlet cachelist = [\n    '/offline.html',\n    'https://npm.elemecdn.com/chenyfan-os@0.0.0-r6'\n];\n```\n\n同时监听sw安装时开启此缓存空间：\n\n```js\nself.addEventListener('install', async function (installEvent) {\n    self.skipWaiting();\n    installEvent.waitUntil(\n        caches.open(CACHE_NAME)\n            .then(function (cache) {\n                console.log('Opened cache');\n                return cache.addAll(cachelist);\n            })\n    );\n});\n```\n\n由于SW完全没有办法访问DOM，因此对于全局变量，不应当用`window`，而是`self`指代自己。\n\n`addEventListener`这一监听器将监听`install`,也就是这一段代码只会在脚本首次安装和更新时运行.\n\n`skipWaiting`的作用是促进新版本sw跳过waiting这一阶段，直接active。\n\n> 关于SW的状态（waiting，installing，activing）将在文后详细解释。\n\n`installEvent.waitUntil`的作用是直接结束安装过程的等待，待会在后台完成开启缓存空间这一操作。\n\n\n`cache.addAll`将会直接获取`cachelist`里面所有的网址并直接缓存到CacheStorage。如果此处网址过多，将在页面加载时疯狂请求所有的url~~(例如1k个)~~\n\n现在，SW初始化已经完成了。接下来，我将讲述SW如何捕获页面的请求。\n\n## 捕获请求 / Fetch Event\n\n### 添加监听器 / AddEventListener\n\n```js\nself.addEventListener('fetch', async event => {\n    event.respondWith(handle(event.request))\n});\n\nconst handle = async(req)=>{\n    //do something\n}\n```\n\n第一行很简单，绑定一个监听器，监听`fetch`事件，即网页向服务器获取请求，也就是相当于前端的`XMLHTTPRequest`\n\n`event.respondWith`即设定返回内容，交给`handle`主函数处理，传参`event.request`。这是一个`Request`对象，里面包含了请求的详细信息。\n\n接下来，我们开始实战吧。\n\n> 以下所有内容均针对handle修改\n\n### 透明代理 / Transparent Proxy\n\n顾名思义，此实战脚本的作用是SW代理目前的所有流量但不进行修改，仿佛SW不存在一般。\n\n```js\nconst handle = async(req)=>{\n    return fetch(req)\n}\n```\n\n`fetch`这个函数相当于前端的`ajax`或者`XMLHTTPRequest`，作用是发起一个请求，获得一个返回值。由于sw不可访问`window`，在sw中是无法使用`ajax`或`XMLHTTPRequest`。同时，`fetch`是一个异步函数，直接调用它会返回一个`Promise`。\n\n`fetch`只能传递`Requset`对象,而`Requset`对象有两个参数`(url,[option])`,第一个参数是网址,第二个参数为`Request`的内容,例如`body`或`header`。\n\n此脚本适用于卸载`ServiceWorker`的替换脚本。因为sw在无法拉取新版本时不会主动卸载，依旧保持运行，填入一个透明代理sw即可。\n\n由于SW冷启动【即页面关闭后SW】处于暂停状态是从硬盘读取的，这会导致第一次请求有少许性能延迟[~10ms]。\n\n### 篡改请求 / Edit Requset\n\n对于一张图片，有时候服务端会变态到让你必须用`POST`协议才能获得，此时用SW篡改最为方便。\n\n```js\nconst handle = async (req) => {\n    if ((req.url.split('/'))[2].match('xxx.com')) {\n        //xxx.com为图片所在域名\n        return fetch(req.url, {\n            method: \"POST\"\n        })\n    }\n    return fetch(req)\n}\n```\n\n> 注意，在ServiceWorker里面，header头是不能修改refferer和origin的，因此此方法无法绕开新浪图床反盗链\n\n### 篡改响应 / Edit Response\n\n这个例子会检测返回内容，若为html，将把所有的\"TEST\"都替换成\"SHIT\"\n\n```js\nconst handle = async (req) => {\n    const res = await fetch(req)\n    const resp = res.clone()\n    if (!!resp.headers.get('content-type')) {\n        if (resp.headers.get('content-type').includes('text/html')) {\n            return new Response((await resp.text()).replace(/TEST/g, 'SHIT'), {\n                headers: resp.headers,\n                status: resp.status\n            })\n        }\n    }\n    return resp\n}\n```\n\n`const resp = res.clone()`由于`Response`的`body`一旦被读取，这个`body`就会被锁死，再也无法读取。`clone()`能够创造出响应的副本用于处理。\n\n`resp.headers.get('content-type')`通过读取响应的头，判断是否包含`text/html`，如果是，将响应以`text()`异步流的方式读取，然后正则替换掉响应内容，并还原头和响应Code。\n\n返回的内容必须是`Response`对象，所以`new Response`构建一个新对象，并直接返回。不匹配html头将直接原封不动地透明代理。\n\n### 移花接木 / Graft Request To Another Server\n\n`unpkg.zhimg.com`是`unpkg.com`的镜像网站。此脚本将会把所有的`unpkg.com`流量直接拦截到`unpkg.zhimg.com`，用于中国大陆内CDN加速。\n\n由于npm镜像固定为GET请求方式并且没有其他鉴权需求，所以我们没有必要还原`Request`其他数据。\n\n```js\nconst handle = async (req) => {\n    const domain = req.url.split('/')[2];\n    if (domain.match(\"unpkg.com\")) {\n        return fetch(req.url.replace(\"https://unpkg.com\", \"https://zhimg.unpkg.com\"));\n    }\n    else {\n        return fetch(req)\n    }\n}\n```\n\n`domain.match`捕获请求中是否有待替换域名，检查出来后直接`replace`掉域名，如果没有匹配到，直接透明代理走掉。\n\n\n\n\n### 并行请求 / Request Parallelly\n\nSW中又一大黑科技隆重登场=>`Promise.any`，这个函数拥有另外两个衍生兄弟`Promise.all`&`Promise.race`。下面我将简单介绍这三种方式\n\n#### Promose.all\n\n当列表中所有的`Promise`都`resolve`[即成功]后，这个函数才会返回`resolve`，只要有一个返回`reject`，整个函数都会`reject`。\n\n```js\nPromise.all([\n    fetch('https://unpkg.com/jquery'),\n    fetch('https://cdn.jsdelivr.net/npm/jquery'),\n    fetch('https://unpkg.zhimg.com/jquery')\n])\n```\n\n这个函数将会请求三个网址，当每一个网址都链接联通后，整个函数将会返回一个列表：\n\n```js\n[Response1,Response2,Response3]\n```\n\n当任何一个`fetch`失败[即`reject`]后，整个`Promise.all`函数都会直接`reject`并报错。\n\n此函数可以检测网络连通性，由于采取并行处理，相比以前的循环效率要高不少。\n\n这是一段检测国内国外网络连通性的测试。\n\n没有采用`Promise.all`的代码和效果：\n\n```js\nconst test = async () => {\n    const url = [\n        \n        \"https://cdn.jsdelivr.net/npm/jquery@3.6.0/package.json\",\n        \"https://unpkg.com/jquery@3.6.0/package.json\",\n        \"https://unpkg.zhimg.com/jquery@3.6.0/package.json\"\n    ]\n    flag = true\n    for (var i in url) {\n        try {\n            const res = await fetch(url[i])\n            if (res.status !== 200) {\n                flag = false\n            }\n        }catch(n){\n            return false\n        }\n    }\n    return flag\n}\n```\n\n![](https://npm.elemecdn.com/chenyfan-os@0.0.0-r7/1.png)\n\n采用循环，`await`会堵塞循环，直到这次请求完成后才能执行下一个。如果有任何一个url长时间无法联通，将会导致极长的检测时间浪费。\n\n\n```js\n\nconst test = () => {\n    const url = [\n        \"https://cdn.jsdelivr.net/npm/jquery@3.6.0/package.json\",\n        \"https://unpkg.com/jquery@3.6.0/package.json\",\n        \"https://unpkg.zhimg.com/jquery@3.6.0/package.json\"\n    ]\n    return Promise.all(url.map(url => {\n        return new Promise((resolve, reject) => {\n            fetch(url)\n                .then(res => {\n                    if (res.status == 200) {\n                        resolve(true)\n                    } else {\n\n                        reject(false)\n                    }\n                })\n                .catch(err => {\n                    reject(false)\n                })\n        })\n\n    }\n    )).then(res => {\n        return true\n    }).catch(err => {\n        return false\n    })\n}\n```\n![](https://npm.elemecdn.com/chenyfan-os@0.0.0-r7/2.png)\n\n`Promise.all`几乎在一瞬间请求所有的url，其请求时并行，每一个请求并不会堵塞其他请求，函数总耗时为最长请求耗时。\n\n#### Promise.race\n\n此函数也是并行执行，不过与all不同的是，只要有任何一个函数完成，就立刻返回，无论其是否`reject`或者`resolve`。\n\n这个函数比较适合用于同时请求一些不关心结果，只要访问达到了即可，例如统计、签到等应用场景。\n\n#### Promise.any\n\n这个函数非常的有用，其作用和`race`接近，不过与之不同的是，`any`会同时检测结果是否`resolve`。其并行处理后，只要有任何一个返回正确，就直接返回哪个最快的请求结果，返回错误的直接忽视，除非所有的请求都失败了，才会返回`reject`\n\n这是一段同时请求`jquery`的`package.json`代码，它将从四个镜像同时请求：\n\n```js\nconst get_json = () => {\n    return new Promise((resolve, reject) => {\n        const urllist = [\n            \"https://cdn.jsdelivr.net/npm/jquery@3.6.0/package.json\",\n            \"https://unpkg.com/jquery@3.6.0/package.json\",\n            \"https://unpkg.zhimg.com/jquery@3.6.0/package.json\",\n            \"https://npm.elemecdn.com/jquery@3.6.0/package.json\"\n        ]\n        Promise.any(urllist.map(url => {\n            fetch(url)\n                .then(res => {\n                    if (res.status == 200) {\n                        resolve(res)\n                    } else {\n                        reject()\n                    }\n                }).catch(err => {\n                    reject()\n                })\n        }))\n    })\n}\n\nconsole.log(await(await get_json()).text())\n```\n\n![](https://npm.elemecdn.com/chenyfan-os@0.0.0-r7/3.png)\n\n函数将会在`21ms`上下返回json中的数据。\n\n此函数的好处在于可以在用户客户端判断哪一个镜像发挥速度最快，并保证用户每一次获取都能达到最大速度。同时，任何一个镜像站崩溃了都不会造成太大的影响，脚本将自动从其他源拉取信息。\n\n除非所有源都炸了，否则此请求不会失败。\n\n但是，我们会额外地发现，当知乎镜像返回最新版本后，其余的请求依旧在继续，只是没有被利用到而已。\n\n这会堵塞浏览器并发线程数，并且会造成额外的流量浪费。所以我们应该在其中任何一个请求完成后就打断其余请求。\n\n`fetch`有一个`abort`对象，只要刚开始`new AbortController()`指定控制器，在`init`的里面指定控制器的`signal`即可将其标记为待打断函数，最后`controller.abort()`即可打断。\n\n那么，很多同学就会开始这么写了:\n\n```js\nconst get_json = () => {\n    return new Promise((resolve, reject) => {\n        const controller = new AbortController();\n        const urllist = [\n            \"https://cdn.jsdelivr.net/npm/jquery@3.6.0/package.json\",\n            \"https://unpkg.com/jquery@3.6.0/package.json\",\n            \"https://unpkg.zhimg.com/jquery@3.6.0/package.json\",\n            \"https://npm.elemecdn.com/jquery@3.6.0/package.json\"\n        ]\n        Promise.any(urllist.map(url => {\n            fetch(url,{\n                signal: controller.signal\n            })\n                .then(res => {\n                    if (res.status == 200) {\n                        controller.abort();\n                        resolve(res)\n                    } else {\n                        reject()\n                    }\n                }).catch(err => {\n                    reject()\n                })\n        }))\n    })\n}\n\nconsole.log(await(await get_json()).text())\n```\n\n但很快，你就会发现它报错了：`Uncaught DOMException: The user aborted a request.`，并且没有任何数据输出。\n\n让我们看一下Network选项卡：\n\n![](https://npm.elemecdn.com/chenyfan-os@0.0.0-r7/4.png)\n\n\n其中，知乎返回的最快，但他并没有完整的返回文件[源文件1.8KB，但他只返回了1.4KB]。这也直接导致了整个函数的`fail`。\n\n原因出在`fetch`上，这个函数在获得响应之后就立刻`resolve`了`Response`，但这个时候`body`并没有下载完成，即`fetch`的返回基于状态的而非基于响应内容，当其中`fetch`已经拿到了完整的状态代码，它就立刻把`Response`丢给了下一个管道函数，而此时`status`正确，`abort`打断了包括这一个`fetch`的所有请求，`fetch`就直接工作不正常。\n \n我个人采取的方式是读取`arrayBuffer`，阻塞`fetch`函数直到把整个文件下载下来。函数名为`PauseProgress`\n\n```js\nconst get_json = () => {\n    return new Promise((resolve, reject) => {\n        const controller = new AbortController();\n        const PauseProgress = async (res) => {\n            return new Response(await (res).arrayBuffer(), { status: res.status, headers: res.headers });\n        };\n        const urllist = [\n            \"https://cdn.jsdelivr.net/npm/jquery@3.6.0/package.json\",\n            \"https://unpkg.com/jquery@3.6.0/package.json\",\n            \"https://unpkg.zhimg.com/jquery@3.6.0/package.json\",\n            \"https://npm.elemecdn.com/jquery@3.6.0/package.json\"\n        ]\n        Promise.any(urllist.map(url => {\n            fetch(url, {\n                signal: controller.signal\n            })\n                .then(PauseProgress)\n                .then(res => {\n                    if (res.status == 200) {\n                        controller.abort();\n                        resolve(res)\n                    } else {\n                        reject()\n                    }\n                }).catch(err => {\n                    reject()\n                })\n        }))\n    })\n}\n\nconsole.log(await(await get_json()).text())\n```\n\n![](https://npm.elemecdn.com/chenyfan-os@0.0.0-r7/5.png)\n\n在这其中通过`arrayBuffer()`方法异步读取`res`的`body`，将其读取为二进制文件，并新建一个新的`Response`，还原状态和头，然后丢给管道函数同步处理。\n\n在这里，我们就实现了暴力并发，以流量换速度的方式。同时也获得了一个高可用的SW负载均衡器。\n\n这一段函数可以这样写在SW中：\n\n\n```js\n//...\nconst lfetch = (urllist) => {\n    return new Promise((resolve, reject) => {\n        const controller = new AbortController();\n        const PauseProgress = async (res) => {\n            return new Response(await (res).arrayBuffer(), { status: res.status, headers: res.headers });\n        };\n        Promise.any(urllist.map(url => {\n            fetch(url, {\n                signal: controller.signal\n            })\n                .then(PauseProgress)\n                .then(res => {\n                    if (res.status == 200) {\n                        controller.abort();\n                        resolve(res)\n                    } else {\n                        reject()\n                    }\n                }).catch(err => {\n                    reject()\n                })\n        }))\n    })\n}\nconst handle = async (req) => {\n    const npm_mirror = [\n        'https://cdn.jsdelivr.net/npm/',\n        'https://unpkg.com/',\n        'https://npm.elemecdn.com/',\n        'https://unpkg.zhimg.com/'\n    ]\n    for (var k in npm_mirror) {\n        if (req.url.match(npm_mirror[k]) && req.url.replace('https://', '').split('/')[0] == npm_mirror[k].replace('https://', '').split('/')[0]) {\n            return lfetch((() => {\n                let l = []\n                for (let i = 0; i < npm_mirror.length; i++) {\n                    l.push(npm_mirror[i] + req.url.split('/')[3])\n                }\n                return l\n            })())\n        }\n    }\n    return fetch(req)\n}\n```\n\n另外,`Promise.any`,兼容性比较差:\n\n![](https://npm.elemecdn.com/chenyfan-os@0.0.0-r9/1.png)\n\n因此,我的解决办法是判断浏览器如果不支持,就提前polyfill一下:\n\n```js\nif (!Promise.any) {\n        Promise.any = function (promises) {\n            return new Promise((resolve, reject) => {\n                promises = Array.isArray(promises) ? promises : []\n                let len = promises.length\n                let errs = []\n                if (len === 0) return reject(new AggregateError('All promises were rejected'))\n                promises.forEach((promise) => {\n                    promise.then(value => {\n                        resolve(value)\n                    }, err => {\n                        len--\n                        errs.push(err)\n                        if (len === 0) {\n                            reject(new AggregateError(errs))\n                        }\n                    })\n                })\n            })\n        }\n    }\n```\n\n## 缓存控制 / Cache\n\n\n### 持久化缓存 / Cache Persistently\n\n对于来自CDN的流量，大部分是持久不变的，因此，如果我们将文件获得后直接填入缓存，之后访问也直接从本地缓存中读取，那将大大提升访问速度。\n\n```js\nconst handle = async (req) => {\n    const cache_url_list = [\n        /(http:\\/\\/|https:\\/\\/)cdn\\.jsdelivr\\.net/g,\n        /(http:\\/\\/|https:\\/\\/)cdn\\.bootcss\\.com/g,\n        /(http:\\/\\/|https:\\/\\/)zhimg\\.unpkg\\.com/g,\n        /(http:\\/\\/|https:\\/\\/)unpkg\\.com/g\n    ]\n    for (var i in cache_url_list) {\n        if (req.url.match(cache_url_list[i])) {\n            return caches.match(req).then(function (resp) {\n                return resp || fetch(req).then(function (res) {\n                    return caches.open(CACHE_NAME).then(function (cache) {\n                        cache.put(req, res.clone());\n                        return res;\n                    });\n                });\n            })\n        }\n    }\n    return fetch(req)\n}\n```\n\n`cache_url_list`列出所有待匹配的域名(包括http/https头是为了避免误杀其他url)，然后`for`开始遍历待列表，如果url中匹配到了，开始执行返回缓存操作。\n\ncache是一个近似于Key/Value(键名/键值)，只要有对应的`Request`(`KEY`)，就能匹配到响应的`Response`(`VALUE`)。\n\n`caches.match(req)`将会试图在CacheStorage中匹配请求的url获取值，然后丢给管道同步函数`then`，传参`resp`为Cache匹配到的值。\n\n此时管道内将尝试返回resp，如果resp为`null`或`undefined`[即获取不到对应的缓存]，将执行fetch操作，fetch成功后将`open`打开CacheStorage，并`put`放入缓存。此时如果`fetch`失败将直接报错，不写入缓存。\n\n在下一次获取同一个URL的时候，缓存匹配到的将不再是空白值，此时`fetch`不执行，直接返回缓存，大大提升了速度。\n\n由于npm的cdn对于latest缓存并不是持久有效的，所以我们最好还是判断一下url版本中是否以@latest为结尾。\n\n```js\nconst is_latest = (url) => {\n    return url.replace('https://', '').split('/')[1].split('@')[1] === 'latest'\n}\n//...\nfor (var i in cache_url_list) {\n    if (is_latest(req.url)) { return fetch(req) }\n    if (req.url.match(cache_url_list[i])) {\n        return caches.match(req).then(function (resp) {\n            //...\n        })\n    }\n}\n```\n\n\n### 离线化缓存 / Cache For Offline\n\n对于博客来说，并不是所有内容都是一成不变的。传统PWA采用SW更新同时刷新缓存，这样不够灵活，同时刷新缓存的版本号管理也存在着很大的漏洞，长时间访问极易造成庞大的缓存冗余。因此，对于博客的缓存，我们要保证用户每次获取都是最新的版本，但也要保证用户在离线时能看到最后一个版本的内容。\n\n因此，针对博客来说，策略应该是先获取最新内容，然后更新本地缓存，最后返回最新内容；离线的时候，尝试访问最新内容会回退到缓存，如果缓存也没有，就回退到错误页面。\n\n即：\n\n```\nOnline:\n发起Request => 发起fetch => 更新Cache => 返回Response\nOffline:\n发起Request => 获取Cache => 返回Response\n```\n\n\n```js\nconst handle = async (req) => {\n    return fetch(req.url).then(function (res) {\n        if (!res) { throw 'error' } //1\n        return caches.open(CACHE_NAME).then(function (cache) {\n            cache.delete(req);\n            cache.put(req, res.clone());\n            return res;\n        });\n    }).catch(function (err) {\n        return caches.match(req).then(function (resp) {\n            return resp || caches.match(new Request('/offline.html')) //2\n        })\n    })\n}\n```\n\n`if (!res) { throw 'error' }` 如果没有返回值，直接抛出错误，会被下面的Catch捕获，返回缓存或错误页面\n\n`return resp || caches.match(new Request('/offline.html'))` 返回缓存获得的内容。如果没有，就返回从缓存中拿到的错误网页。此处offline.html应该在最开始的时候就缓存好\n\n## 持久化存储 / Storage Persistently\n\n由于sw中无`window`，我们不能使用`localStorage`和`sessionStorage`。SW脚本会在所有页面都关闭或重载的时候丢失原先的数据。因此，如果想要使用持久化存储，我们只能使用`CacheAPI`和`IndexdDB`。\n\n### IndexdDB\n\n这货结构表类型类似于`SQL`，能够存储JSON对象和数据内容，但版本更新及其操作非常麻烦，因此本文不对此做过多解释。\n\n### CacheAPI\n\n这东西原本是用来缓存响应，但其本身的特性我们可以将其改造成一个简易的Key/Value数据表，可以存储文本/二进制，可扩展性远远比IndexdDB要好。\n\n```js\nself.CACHE_NAME = 'SWHelperCache';\nself.db = {\n    read: (key) => {\n        return new Promise((resolve, reject) => {\n            caches.match(new Request(`https://LOCALCACHE/${encodeURIComponent(key)}`)).then(function (res) {\n                res.text().then(text => resolve(text))\n            }).catch(() => {\n                resolve(null)\n            })\n        })\n    },\n    read_arrayBuffer: (key) => {\n        return new Promise((resolve, reject) => {\n            caches.match(new Request(`https://LOCALCACHE/${encodeURIComponent(key)}`)).then(function (res) {\n                res.arrayBuffer().then(aB => resolve(aB))\n            }).catch(() => {\n                resolve(null)\n            })\n        })\n    },\n    write: (key, value) => {\n        return new Promise((resolve, reject) => {\n            caches.open(CACHE_NAME).then(function (cache) {\n                cache.put(new Request(`https://LOCALCACHE/${encodeURIComponent(key)}`), new Response(value));\n                resolve()\n            }).catch(() => {\n                reject()\n            })\n        })\n    }\n}\n```\n\n使用操作：\n\n写入key，value:\n\n```js\nawait db.wtite(key,value)\n```\n\n以文本方式读取key：\n\n```js\nawait db.read(key)\n```\n\n以二进制方式读取key：\n\n```js\nawait db.read_arrayBuffer(key)\n```\n\n其余的blob读取、delete操作此处不过多阐述。\n\n\n## 页面与SW通信 / Build Communication with Page and ServiceWorker\n\n### 单向连接 / Unidirectional Connect\n\n### Clients To SW\n\n浏览器 => SW\n\nServiceWorker中有一个非常简单的API`postMessage`,全路径为`navigator.serviceWorker.controller.postMessage`.\n\n因此,如果你只是作为页面单方面传递给SW,此api是个不错的选择.\n\n前端写法\n\n```js\nconst data = 123\nnavigator.serviceWorker.controller.postMessage(data)\n//发送123\n```\n\nSW接收\n\n```js\nself.addEventListener('message', (event) => {\n  console.log(event.data)\n  //输出123\n});\n```\n\n此方法可用于单方面向SW提交数据,但无需返回值.比如提示SW可以SkipWaiting,或者提交前端统计数据等等.\n\n\n#### SW To Clients\n\n首先,Clients必须要从SW中的一个event事件中获取,比如`fetch`.无法从`message`事件中获取client.\n\n```js\naddEventListener('fetch', event => {\n    event.waitUntil(async function () {\n        if (!event.clientId) return;\n        const client = await clients.get(event.clientId);\n        if (!client) return;\n        const data = 123;\n        client.postMessage(data);\n    }());\n});\n```\n\n### 双向通讯 / Connect Each\n\n浏览器 <=> SW\n\n我们拥有两种方式双向通讯:\n\n1. [Broadcast Channel API](https://developer.mozilla.org/en-US/docs/Web/API/Broadcast_Channel_API) 多对多,广播形式.\n2. [Message Channel](https://developer.mozilla.org/en-US/docs/Web/API/MessageChannel) 一对一\n\n\n\n#### MessageChannel\n\n顾名思义，MessageChannel API 设置了一个可以发送消息的通道。\n\n该实现可以归结为3个步骤。\n\n1.在两侧设置事件侦听器以接收`message` 事件\n2.通过发送`port`并将其存储在SW中，建立与SW的连接。\n3.使用存储的`port`回复客户端\n\n前端写法\n\n```js\nconst messageChannel = new MessageChannel();\nnavigator.serviceWorker.controller.postMessage({\n  type: 'INIT',//发送init信息,表示以port2为接收端[即SW的发送端]\n}, [messageChannel.port2]);\nmessageChannel.port1.onmessage = (event) => {\n  //监听port1\n  navigator.serviceWorker.controller.postMessage({\n    type: 'PING'//发送PING\n  });\n};\n```\n\n\nSW端写法\n\n```js\nself.addEventListener(\"message\", event => {\n    const data = event.data;\n    if (!!data) {\n        switch (data.type) {\n            case 'INIT':\n                self.ClientPort = event.ports[0];\n            default:\n                self.ClientPort.postMessage({\n                    type: 'DATA',\n                    data: 'pong'\n                });\n        }\n    }\n})\n```\n\n然后查看控制台,你就会看到里面一直在乒乒乓乓,说明成功了.\n\n我们简单的改写一下,变成异步形式传输数据:\n\n```js\nconst mCh = {\n        init: () => {\n            window.messageChannel = new MessageChannel();\n            navigator.serviceWorker.controller.postMessage({\n                type: 'INIT',\n            }, [messageChannel.port2]);\n        },\n        send: (data) => {\n\n            return new Promise((resolve, reject) => {\n                const uuid = (() => {\n                    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function (c) {\n                        var r = Math.random() * 16 | 0, v = c == 'x' ? r : (r & 0x3 | 0x8);\n                        return v.toString(16);\n                    });\n                })()\n                navigator.serviceWorker.controller.postMessage({\n                    type: 'DATA',\n                    data: data,\n                    id: uuid\n                });\n                setTimeout(() => {\n                    reject({\n                        message: 'timeout',\n                        ok: false\n                    })\n                }, 2000);\n                messageChannel.port1.onmessage = (event) => {\n                    if (event.data.id === uuid) {\n                        resolve({\n                            message: event.data.data,\n                            ok: true\n                        })\n                    };\n                }\n            })\n        }\n    }\n```\n\n由于MessageChannel特性,一个port只要不是连续传输数据就会被断开.所以每次传输时我们要先初始化,后发送数据.\n\n由于传输时无状态的,我们将每一个包都打上特定的uuid,返回包里也写上对应的uuid即可判断那个包是哪个对应的返回值.\n\nSW端也要做一点点相应的改动\n\n```js\nself.ClientPort.postMessage({\n//...\nid: data.id\n});\n```\n\n这样,一个兼容性较好的SW双向传输就解决了.\n\n#### Broadcast Channel \n\n> 请注意,BroadCast虽然写法建议,但是对浏览器兼容性要求非常高[Chrome 54,IOS Safari全线不支持].用此api请三思.\n\n> 另外,由于是广播形式,一个页面如果有多个SW,他们会同时收到消息.\n\n前端\n\n```js\nconst broadcast = new BroadcastChannel('Channel Name');\nconst send_ping = () => {\n    broadcast.postMessage({\n        type: 'PING'\n    });\n}\nbroadcast.onmessage = (event) => {\n    console.log('PONG')\n    setTimeout(() => {\n        send_ping()\n    }, 500);\n};\nsend_ping()\n```\n\nSW端\n\n```js\nconst broadcast = new BroadcastChannel('Channel Name');\nbroadcast.onmessage = (event) => {\n    broadcast.postMessage({ type: \"PONG\" })\n};\n```\n\n只要ChannelName对应,即可在里面顺利传输消息.\n\n\n## 细节与注意 / Something Small But Need to Be Mentioned\n\n### 无法修改的 Header\n\n由于ServiceWorker本质上仍然属于浏览器,因此,你无法控制例如header中的`Host`\\\\`Refferer`\\\\`Access-Control-Allow-Origin`用于绕过防盗链\\CORS\\指定host选择ip\n\n\n### 难以卸载的 SW\n\nSW一大特性,一旦被安装,就不能通过传统方式卸载掉.\n\n如果你直接删除`sw.js`文件并删除安装代码,那么,新用户是不会被安装的,但是原先已经安装过的用户sw会继续劫持这他们的网页,导致老用户网页不更新或者出现异常.\n\n正确的删除方法是将安装代码改成卸载代码:\n\n```\nnavigator.serviceWorker.getRegistrations().then(function(registrations) {\n for(let registration of registrations) {\n  registration.unregister()\n} })\n```\n\n并将sw内容改成透明代理,方便没有卸载的用户正常使用.\n\n\n### 堵塞整个浏览器的代码\n\n由于SW运行在DOM上下文,如果在sw中执行一些消耗资源的代码会直接耗尽浏览器资源,与dom不同的是,dom耗资源代码只会堵塞一个线程,另一个线程依旧可以正常工作,而sw一旦堵塞会将整个浏览器堵死.因此sw固然可以更快的计算,但万不可将一些极易死机的代码交给sw处理.\n\n\n\n\n# End\n\n这篇文章结尾的很仓促,毕竟已经快拖了一个月了,也有很多东西没有讲清楚,未来可能会小修小改.\n\n篇幅所限,一些sw其他功能并没有详细讲述,比如后台更新或者推送通知.这些功能在实际开发中并不是特别有用,或者在国内大环境下并不适合.可能这些功能会在下一篇文章,sw的实操中讲述.\n\n停下笔的时候,hexo统计这篇文章已经将近1万字,阅读时间近100分钟.不过我认为这值得,毕竟sw就是这么一个凭借着奇思妙想就能绽放出Spark的事物.唯有独特的创造力才能激发无限可能.\n\n当然,这篇文章讲述的都是些非常基础的东西,那在下一篇文章,我会贴出一个个demo,希望你们能对这些充满着智慧的样例激发你们的灵感.\n\n另外,在祝贺你们,虎年大吉,新年快乐!","tags":["ServiceWorker","黑科技","JSdelivr"],"categories":["随心扯"]},{"title":"为什么是APP而不是网页","url":"/p/c0af86a9.html","content":"\n一个简单的功能，完全可以在浏览器内实现，凭什么国内某些软件这么希望你去下载，去使用他们的app？\n\n<!--more-->\n\n就在不久前，我是真的体会到了什么叫流氓厂商。点名批评一下百度，我苹果手机Safari随便在百度上搜索点什么，还没把营销号、广告和垃圾信息从眼中剔除，突然间，AppStore界面平移到我眼前，一个叫`百度`的软件可怜巴巴的望着我。于是我点击左上角返回键，然后继续搜索...\n\n这不是一件在国内很常见的事情吗，然后我继续浏览，点击一个百度百科网页链接，又是还没开看，appstore显示了出来，这次是百度百科app。\n\n好，没事，我平复了一下心情，整理了一下被打乱的思绪，继续浏览着百科，滑到页面底部，加载新的内容时，一个弹窗显示出来：使用百度百科APP，获取更好的浏览体验！\n\n关闭，继续浏览。\n\n点击百科内部的内链，尝试跳转到另一个百科界面，突然，浏览器一片空白，我又被引导向appstore。\n\n很抱歉，我直接关闭了百度，使用谷歌和维基百科继续查询资料。这一次，谷歌虽然也在下方提示【在IOS上尝试使用谷歌桌面版，获取更好的体验】，但至始至终没有把我强制跳到appstore。维基百科就更不用说了，连使用app都没有提示。\n\n退出了浏览器，我不禁陷入了沉思。我还记得不久前拿到朋友的新鸿蒙手机，划开屏幕一看，第一个界面全是百度系列：百度、百度搜索、百度智能浏览器、百度贴吧、百度知道...一个个功能冗余的百度app赫然显示在我的眼前，当我一脸震惊地看向朋友，他耸耸肩：点进去就自己下载的，不安装就没办法看了。\n\n看着自己苹果手机中的两个一个浏览器：Safari和Alook，我停止了思考，当一个大厂天天为自己的免费网盘带宽叫屈，下载一个3M的电子书被限成一副狗样时，你还能相信他有这么大的带宽给用户推自己的动辄100MB的APP？这能算是本末倒置吗？\n\n从此，我在手机上再也没有用过百度系。必应和谷歌，DogeDoge和DuckDuckGo成为了我的搜索主力。\n\n# 为什么是APP\n\n## 隐私\n\n\napp对隐私的疯狂到了什么地步？\n\n在安卓环境【尤其是国内某些套壳系统】下，app的权限不算小，有些时候可以在没有提醒的情况下把你的浏览器记录翻个遍。\n\nios其实相对安卓来说，至少系统能主动提醒用户是否给予其访问权利。\n\n这一点我也十分佩服MIUI，能在这种隐私岁随意获取风气下站住来守住用户的底线，无论其目的如何，这一点已经赢得了我的好感【虽然我不用安卓】\n\n对于软件商来说，用户的数据是一大笔财富。比如知道所有人的喜好、购买能力等，这些信息掌握得越细致，越能挖掘到更多的商机。\n\n暂且不说百度，就连TIM和QQ也会主动扫描用户Chrome浏览记录<span class=\"heimu\">~~我靠那我的nhentai浏览记录怎么办~~</span>\n\n## 互唤醒【For安卓】\n\n为了实现广告营销，部分软件实际上要向用户主动推送广告信息。\n\n尤其是安卓，由于谷歌市场退出中国大陆，国内安卓生态其实很乱，一个简单的消息推送，也能难倒一群开发者。\n\n为什么消息推送变成了一个难题？其实我们想象中的消息推送与实际上的方式有很大差距:\n\n想象中：用户手机<==主动推送==微信服务器\n实际上：用户手机<==被动推送==>苹果|安卓消息推送服务器<==主动推送==微信服务器\n\n苹果还好说，18年以前经常会出现微信无法推送的情况，但自从大陆线路优化以及云上贵州的迁移，其推送服务逐渐变得正常。然而谷歌早已退出中国市场，其内置的推送服务器已经不可链接，请问这些app这么办？\n\n答：常驻系统后台。\n\n但是常驻系统后台成为一个Zombine进程也不可避免会被杀掉，请问这又能怎么办？\n\n答：相互唤醒。\n\n当用户打开一个app，此app会在后台激活另一群app，然后如果当前app被杀了，被激活的app又会激活那个被杀的app。\n\n这样就很好理解了虽然只有百度app才会推送广告，但他依旧会引导你去下载百度浏览器---避免被杀掉啊。\n\n# 为什么不是浏览器应用\n\n## 隐私\n\n在这个隐私即金钱的时代，对于国内厂商来说，首先一个遗憾的事情是，浏览器是很难获取到用户的隐私信息。不是说功能限制，而是浏览器其核心就是沙盒化。在没有用户同意和外接接口、插件的前提下，你不可能直接用js获取到用户手机/电脑上的文件。\n\n而且最致命的是，如果网页应用敢在后台偷偷上传用户隐私，控制台一开就会使其暴露无遗，相对比APP的黑盒操作，那简直是天差地别。\n\n## 功能限制\n\njs功能其实很强大，但有些底层和协议上的限制不能做就是不能做，你不可能用js空手写一个SMTP发送邮件，你也不可能直接用SSH协议链接服务器【WebSSH需要在服务器主动安装服务端】\n\n其次，一些十分耗资源和计算力的服务不可能在浏览器上实现，比如腾讯不可能把王者荣耀搬到浏览器上，你也不可能在浏览器里跑机器学习。\n\n## 网络限制\n\n如果使用浏览器，其每一次打开服务网店都要重新下载上面的js、css和图片资源，这一瞬间爆发对服务器压力其实不小。\n\n而使用app，他可以事先在后台下载好广告图片，其样式和功能无需重新下载，并且很多资源可以缓存在本地，即使短暂离线也能推送。\n\n这一点，PWA技术完全可以胜任。PWA通过在浏览器内ServiceWorker拦截和缓存内容实现离线浏览。但目前来讲PWA技术在国内不温不火【很明显，触碰到了某些企业的利益】，所以还是以应用程序为主。\n\n<span class=\"heimu\">但是，你这样剩下来的流量费还是比不过强制更新来的多啊</span>\n\n# 为什么国外没有出现类似的情况\n\n## 监管缺失\n\n海外，安卓应用最官方的商店只有一家：GooglePlay，虽然不像AppStore那种不上架连安装都不给的程度，但也是一种象征。没有上架谷歌商店的应用基本都会被判定为盗版或者危险。而且谷歌play对广告监管很严。如果一个应用敢像百度般，疯狂推送广告和自唤醒，可能连安全审查都过不去。\n\n在国内，连老大都管不了，宛若袁世凯暴毙天下军阀混战，其乱象不言而喻。\n\n## 隐私意识缺乏\n\n李彦宏有句~~名言~~：中国人更愿意用隐私交换便捷性。\n\n虽然此话一出被无数网友嘲讽，但也不得不承认这确实如此。甚至有些时候自己也是被迫的。没有多少人会上网的时候开无数个虚拟机中继代理AdGuard，相反，有更多人为了PDD的几分钱蔬菜而抢破头。一句话：国人都喜欢薅羊毛，但最终都会成为韭菜被割。\n\n相反，在国外，人们对于隐私十分看重，哪怕GoogleAdsense都被罚了好几次，还不用说Tor之类的隐私保护软件。\n\n## 使用观念的不同\n\n我个人的习惯是，完成一件事情，用什么东西都越轻越好，不是有必要就不下客户端。比如在电脑微信接收消息，你可以选择下载微信客户端完成传输，也可以用[网页微信](https://wx.qq.com)。相较于前者，后者用完就关，不留痕迹，速度也快。\n\n然而国人的习惯大多是：先下载下来，万一以后有用呢。\n\n当我看到电视上的手机广告，大多8H16G运存128G内存起步，盯着手里这台国产只装了QQ到2021年还能打Minecraft的iPhone6s【实际配置2GB运存A9处理器】，不禁留下了悔恨的泪水：幸好没买安卓。\n\n安卓手机即使内存再大，其底层核心还是虚拟化，加上国内的恶劣的生态，如果你不留神多下点软件，其流畅度甚至比不过6年前的6s。\n\n而手机卡，大多数人的第一个想法是：换一台手机。而不是：我删掉点软件，只保留QQ和微信。\n\n尤其是，在国内的内循环已经完成的前提下，更多人选择了买爱国手机，装爱国软件。实际上，留一条隐私底线其实也没有什么。但偏偏有人喜欢把自己隐私送给别人。\n\n# 后言\n\n实际上，绝大多数软件从C/S架构向B/S架构的转换是不可避免的。但是国内的生态似乎在阻碍着这一发展。\n\n或许有人会问，隐私再保护有什么用。那我只能说，如果你的隐私在黑市只能卖1毛钱一条，那隐私保护的好的人或许能卖5块钱一条。真正的危害其实不在于精准推送，而更怕有人会拿去做违法事情，暴力你，诈骗你。","tags":["应用","浏览器","隐私","app"],"categories":["叨叨念"]}]